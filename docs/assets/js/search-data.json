[{"doc":"Root","title":"Root","hpath":"root","content":"\n![DeltaManiac](https://raw.githubusercontent.com/DeltaManiac/DeltaManiac/main/vault/assets/banner.svg)\n\n- üî≠ I‚Äôm currently playing Destiny 2\n- üå± I‚Äôm currently learning [Rust](https://www.rust-lang.org) at night and [Go](https://golang.org/) at work\n- üì´ How to reach me: [twitter](https://twitter.com/Delta_Maniac)\n- üòÑ Pronouns: He/Him\n- ‚ö° Fun fact: The banner was provided by [Pushkar Anand](https://github.com/pushkar8723) sourced from [Responsive Cow Jumps Over the Moooooon](https://codepen.io/sdras/pen/doZReX)\n<!-- // - üëØ I‚Äôm looking to collaborate on ...\n// - ü§î I‚Äôm looking for help with ...\n// - üí¨ Ask me about ... -->\n","url":"https://deltamaniac.github.io","relUrl":"/"},{"doc":"Todo","title":"Todo","hpath":"todo","content":"\n\n# ToDo BucketList\n\n- [ ] Headcrab\n  - [ ] ELF\n    - [ ] Thread Local for x86-64\n      https://akkadia.org/drepper/tls.pdf\n  - [ ] Dwarf\n    http://dwarfstd.org/doc/Debugging%20using%20DWARF-2012.pdf\n  - [x] Cirrus Build Conf\n- [x] Kafka üìñ\n  https://assets.confluent.io/m/1b509accf21490f0/original/20170707-EB-Confluent_Kafka_Definitive-Guide_Complete.pdf\n- [x] Distributed Design\n  https://azure.microsoft.com/mediahandler/files/resourcefiles/designing-distributed-systems/Designing_Distributed_Systems.pdf\n- [x] Migrate from old blog to new blog\n- [x] Reddit Bot for Youtube PlayList\n- [x] Cloud Events\n- [ ] k8s + Nats.io\n- [ ] Little Man Computer\n  - [ ] WASM Support\n- [x] Advent of Code 2020\n\n","url":"https://deltamaniac.github.io/notes/42bff885-549f-422e-8ef8-d17ecd01ca52.html","relUrl":"notes/42bff885-549f-422e-8ef8-d17ecd01ca52.html"},{"doc":"Rust","title":"Rust","hpath":"rust","content":"# Rust\n\n## Reddit Bot\n\n[[Vyom Bot | rust.bots.reddit]]\n\n\n## Kafka\n\n[[Producer | kafka.producer]]\n\n[[Consumer | kafka.consumer]]\n","url":"https://deltamaniac.github.io/notes/18962325-b097-4283-9f8e-23a89a24511b.html","relUrl":"notes/18962325-b097-4283-9f8e-23a89a24511b.html"},{"doc":"Bots","title":"Bots","hpath":"rust.bots","content":"\n","url":"https://deltamaniac.github.io/notes/947feb8a-ba58-4fd9-85fb-c599a93c13f3.html","relUrl":"notes/947feb8a-ba58-4fd9-85fb-c599a93c13f3.html"},{"doc":"Reddit","title":"Reddit","hpath":"rust.bots.reddit","content":"\n# Vyom\n\nThe surmised version of how to write a Reddit Bot in [[rust]]\n\n# Part I\n\nRecently while browsing [reddit](https://old.reddit.com) I came up on a [post](https://www.reddit.com/r/rust/comments/i1satq/webference_rusty_days_2020_all_recorded_talks/g01rwq8/?context=3) in the [/r/rust](https://old.reddit.com) subreddit which was a link to a YouTube playlist for the Rusty-Days conference, however there was no way I could find the contents of the playlist without going to YouTube on my phone. This was a nuance so I went to YouTube and curated the list.\n\n![](/assets/images/2020-10-11-18-16-48.png)\n\n\nThis was going to be tiresome if I'd have to do it every time I see a post that links to a YouTube playlist. So here we are writing a bot do this task for everyone. This bot will run on a server somewhere (hopefully forever) and curate playlist info for all the people who avail its service.\n\n# Creating Credentials For Our Bot\n\nIn order to write our bot we first need to get some credentials from reddit so that we can access [reddit apis](https://old.reddit.com/dev/api) programmatically.\n\nFirst we need an application id and secret so that reddit can know our application. We can get this information by going to [preferences/app](https://www.reddit.com/prefs/apps) and clicking `are you a developer? create an app...` button cause **we definitely are.**\n\nReddit lets us choose the type of the app we want to build. The three types of app are :\n\n- Web app: Runs as part of a web service on a server you control. Can keep a secret.\n\n- Installed app: Runs on devices you don't control, such as the user's mobile phone. Cannot keep a secret, and therefore, does not receive one.\n\n- Script app: Runs on hardware you control, such as your own laptop or server. Can keep a secret. Only has access to your account.\n\nMore info about about the apps can be found [here](https://github.com/reddit-archive/reddit/wiki/oauth2-app-types).\n\nWe choose the `script` type, enter a name and description for our bot, and use the dummy url `http://www.example.com/unused/redirect/uri` for the redirect url.\n\n![](/assets/images/2020-10-11-18-17-29.png)\n\nWe have now created the credentials with Client Id : `TjC0s2uTaTHYCg` and Client Secret : `mrkAaWitnXLf_DiRagIRS_33cD8`.\n\n![](/assets/images/2020-10-11-18-18-29.png)\n\n# Using and Storing the credentials\n\nWe can now hard code the credentials in our source code and use like this.\n\n```rust\n# main.rs\n\nstatic  CLIENT_ID:&str=\"TjC0s2uTaTHYCg\";\nstatic  CLIENT_SECRET:&str=\"mrkAaWitnXLf_DiRagIRS_33cD8\";\n\nfn main(){\n    println!(\"Client ID: {}\",CLIENT_ID);\n    println!(\"Client Secret: {}\",CLIENT_SECRET);\n}\n```\n\n```shell\nDeltaManiac @ ~/git/rust/vyom\n‚îî‚îÄ $ cargo run\n    Finished dev [unoptimized + debuginfo] target(s) in 0.08s\n     Running `target/debug/vyom`\nClient ID: SmQ7CzGkKA62yA\nClient Secret: UItY35BYBEN_rFVnGVzud9Pig6g\n```\n\nThis is a very easy and clear way to handle credentials but it is flawed.\n\n- If we need to change the credentials then we would have to change the code, rebuild the app and restart the app.\n\n- If we decide to share the code with someone or push it github, it will expose our credentials, which can be used to hijack our account and do bad things.\n\nSo lets see if we can fix the first problem, by moving the credentials out of the source code. But where do we put it then ? If you're thinking about environment variables then you're absolutely right. Environment variables are a good place to store such values and they are fairly easy to change.\n\n```rust\n# main.rs\n\nfn main(){\n    match std::env::var(\"CLIENT_ID1\") {\n        Ok(client_id) => println!(\"Client ID: {}\", client_id),\n        Err(e) => panic!(\"Couldn't read CLIENT_ID ({})\", e),\n    };\n    match std::env::var(\"CLIENT_SECRET1\") {\n        Ok(client_secret) => println!(\"Client Secret: {}\", client_secret),\n        Err(e) => panic!(\"Couldn't read CLIENT_SECRET ({})\", e),\n    };\n}\n```\n\nSince our bot wont work without a `client_id` and a `client_secret` we call [panic!](https://doc.rust-lang.org/stable/std/macro.panic.html) so that the application exits with an error.\n\n```shell\n(base) DeltaManiac @ ~/git/rust/vyom\n‚îî‚îÄ $ cargo run\n    Finished dev [unoptimized + debuginfo] target(s) in 0.41s\n     Running `target/debug/vyom`\nthread 'main' panicked at \\'Couldn\\'t read CLIENT_ID (environment variable not found),\nsrc/main.rs:9:19\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\n\n# Set the environment variables\n(base) DeltaManiac @ ~/git/rust/vyom\n‚îî‚îÄ $ export CLIENT_SECRET=UItY35BYBEN_rFVnGVzud9Pig6g\n(base) DeltaManiac @ ~/git/rust/vyom\n‚îî‚îÄ $ export CLIENT_ID=SmQ7CzGkKA62yA\n\n(base) DeltaManiac @ ~/git/rust/vyom\n‚îî‚îÄ $ cargo run\n    Finished dev [unoptimized + debuginfo] target(s) in 0.47s\n     Running `target/debug/vyom`\nClient ID: SmQ7CzGkKA62yA\nClient Secret: UItY35BYBEN_rFVnGVzud9Pig6g\n```\n\nMost of the time we don't really want to export a lot of environment variables manually. It is exhausting. We could fix this problem by writing a shell script that has all our `export` statements... or we can use [dotenv](https://crates.io/crates/dotenv). Dotenv is a crate that provides us a way to put environment variables in a `.env` file and read them. Dotenv is smart to enough to only read from the file if the Environment Variable is **not set** on the system.\n\nWe first add the `dotenv` dependency to our `Cargo.toml` file.\n\n```toml\n# Cargo.toml\n[package]\nname = \"vyom\"\nversion = \"0.1.0\"\nauthors = [\"DeltaManiac <maxpaynered@gmail.com>\"]\nedition = \"2018\"\n\n[dependencies]\ndotenv_codegen=\"0.15.0\" # dotenv dependency\n```\n\nWe then setup the environment variables in the `.env` file.\n\n```shell\n# .env\nCLIENT_ID=test_123\nCLIENT_SECRET=test_321\nTest=DeezTests\n```\n\nWe finally modify our code to use the `dotenv` crate.\n\n```rust\n# main.rs\n\n#[macro_use]\nextern crate dotenv_codegen;\n\nfn main(){\n    println!(\"Env Not on Sys: {}\",dotenv!(\"Test\"));\n    println!(\"Client ID: {}\",dotenv!(\"CLIENT_ID\"));\n    println!(\"Client Secret: {}\",dotenv!(\"CLIENT_SECRET\"));\n}\n```\n\n```shell\n(base) DeltaManiac @ ~/git/rust/vyom\n‚îî‚îÄ $ cargo run\n    Finished dev [unoptimized + debuginfo] target(s) in 0.08s\n     Running `target/debug/vyom`\nEnv Not on Sys: ss #Value from the .env file\nClient ID: SmQ7CzGkKA62yA #Value from the system\nClient Secret: UItY35BYBEN_rFVnGVzud9Pig6g #Value from the system\n```\n\n# How will the bot work ?\n\nThe bot will listen to a mention like `/u/VyomBot` and would check if the post is a link to a YouTube playlist or at a later stage if the parent comment of the mention is a YouTube playlist.\n\n# Setting up Reddit\n\nWe can follow these steps to setup reddit for testing/developing this bot\n\n1. Created a new user called [VyomBot](https://old.reddit.com/user/VyomBot) so that the bot can be mentioned via `/u/VyomBot`\n\n2. Registered a new app of `script` type for `/u/VyomBot`\n\n3. Create a new [subreddit](https://old.reddit.com/ur/VyomBot) `/r/VyomBot` as a test play ground.\n\n![](/assets/images/2020-10-11-18-20-37.png)\n\n4. Create a new [post](https://www.reddit.com/r/VyomBot/comments/i6fk15/test_playlist/?) with the link to the playlist.\n\n5. Mention `/u/VyomBot` in the comments.\n\n![](/assets/images/2020-10-11-18-21-13.png)\n\n# Talking to Reddit\n\n## Getting Messages from Inbox\n\nLets start off by querying reddit to see if we have a new mention and printing the message. We will use the [roux](https://crates.io/crates/roux) crate for interacting with the reddit apis.\nDirect quote from the description of the crate\n\n> A simple, asynchronous Reddit API wrapper implemented in Rust.\n\nThis means that we have to use a framework like [tokio](https://crates.io/crates/tokio) to provide the async runtime for our bot.\nLets go about doing that.\n\nAdd the dependencies to our Cargo.toml file.\n\n```toml\n# Cargo.toml\n[package]\nname = \"vyom\"\nversion = \"0.1.0\"\nauthors = [\"DeltaManiac <maxpaynered@gmail.com>\"]\nedition = \"2018\"\n\n[dependencies]\ndotenv_codegen=\"0.15.0\" # dotenv dependency\nroux=\"1.0.0\" # roux dependency\ntokio = {version=\"0.2.22\",features=[\"macros\"]} # tokio dependency and only enable the macro feature\n```\n\nUpdate our code to use the library and call the reddit apis.\n\n```rust\n# main.rs\n\n#[macro_use]\nextern crate dotenv_codegen;\n#[macro_use]\nextern crate log; // Used for logging\nuse roux::Reddit;\n\n#[tokio::main]\nasync fn main() {\n    match Reddit::new(\n        dotenv!(\"VYOM_USERAGENT\"),\n        dotenv!(\"VYOM_CLIENT_ID\"),\n        dotenv!(\"VYOM_CLIENT_SECRET\"),\n    )\n    .username(dotenv!(\"VYOM_USERNAME\"))\n    .password(dotenv!(\"VYOM_PASSWORD\"))\n    .login()\n    .await\n    {   // Try to make a new client with the credentials\n        Ok(client) => match client.inbox().await {\n            // Fetch the inbox of the logged in user\n            Ok(listing) => {\n                println!(\"Message Count {}\", listing.data.children.len());\n                dbg!(listing.data.children.get(0).unwrap());\n            }\n            Err(_) => {\n                error!(\"Failed to fetch messages\");\n            }\n        },\n        Err(e) => panic!(e),\n    }\n}\n\n```\n\nWhen we run the program we get the number of messages we have and the `dbg!` macro shows what the passed in variable which in this case is a `InboxItem` struct, looks like.\n\n```shell\n(base) DeltaManiac @ ~/git/rust/vyom\n‚îî‚îÄ $ cargo run\n    Finished dev [unoptimized + debuginfo] target(s) in 3.71s\n     Running `target/debug/vyom`\nMessage Count 5\n[src/main.rs:24] &listing.data.children.get(0).unwrap().data = InboxItem {\n    id: \"g0vfbra\",\n    subject: \"username mention\",\n    was_comment: true,\n    author: Some(\n        \"DeltaManiac\",\n    ),\n    parent_id: Some(\n        \"t3_i6fk15\",\n    ),\n    subreddit_name_prefixed: Some(\n        \"r/VyomBot\",\n    ),\n    new: true,\n    type: \"username_mention\",\n    body: \"/u/VyomBot\",\n    dest: \"VyomBot\",\n    body_html: \"&lt;!-- SC_OFF --&gt;&lt;div class=\\\"md\\\"&gt;&lt;p&gt;&lt;a href=\\\"/u/VyomBot\\\"&gt;/u/VyomBot&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;\",\n    name: \"t1_g0vfbra\",\n    created: 1596987973.0,\n    created_utc: 1596959173.0,\n    context: \"/r/VyomBot/comments/i6fk15/test_playlist/g0vfbra/?context=3\",\n}\n```\n\nWe can use the `new` property to identify if this is a message that we had previously read.\nThe type property can be used to determine if the item is a comment or a username mention.\nWe can use this to iterate over the messages retrieved and and determine the messages that we have to reply to.\n\n# Replying to the message\n\nRoux provides us a convenient method aptly name `comment` to reply to the message. Let's go ahead and use this to reply to the message.\n\n```rust\n# main.rs\n\nasync fn main() {\n...\n...\n// Fetch the inbox of the logged in user\n    Ok(listing) => {\n        for message in listing.data.children.iter() {\n            is message unread and of type \"username_mention\"\n            if message.data.new && message.data.r#type == \"username_mention\" {\n                match client\n                    .comment(\n                        \"You have been Noted by Vyom. Please Stand By!\",\n                        &message.data.name.as_str(),\n                    )\n                    .await\n                {\n                    Ok(_) => info!(\"Replied to {}\", message.data.name),\n                    Err(_) => error!(\"Failed to reply to mention\"),\n                };\n            }\n        }\n    }\n...\n...\n```\n\n> Psst.., I'll let you in on something cool. In rust `type` is a reserved keyword. In most programming languages you can use a keyword only as keyword, e.g. you _cannot_ have a variable called `for`. In rust we can use `type` as an attribute of a struct and access it by specifying it as a raw string using the `r#` like `message.data.r#type`\n\nNow that we have written the code lets run it and see what happens..\n\n```shell\n(base) DeltaManiac @ ~/git/rust/vyom\n‚îî‚îÄ $ cargo run\n    Finished dev [unoptimized + debuginfo] target(s) in 4.45s\n     Running `target/debug/vyom`\n```\n\nNice! It logged that we replied to the mention. Lets run it again, this time it should not reply to an already replied message as we have read it.\n\n```shell\n[2020-08-09T12:59:25Z INFO  vyom] Replied to t1_g0vfbra\n(base) DeltaManiac @ ~/git/rust/vyom\n‚îî‚îÄ $ cargo run\n    Finished dev [unoptimized + debuginfo] target(s) in 0.10s\n     Running `target/debug/vyom`\n[2020-08-09T12:59:29Z INFO  vyom] Replied to t1_g0vfbra\n(base) DeltaManiac @ ~/git/rust/vyom\n‚îî‚îÄ $ cargo run\n    Finished dev [unoptimized + debuginfo] target(s) in 0.09s\n     Running `target/debug/vyom`\n[2020-08-09T12:59:32Z INFO  vyom] Replied to t1_g0vfbra\n```\n\nDamn!\nIT REPLIED AGAIN!!!üòû\nAnd this is what the subreddit looks like now.\n\n![](/assets/images/2020-10-11-18-22-14.png)\n\nTime to find that pesky bug and get rid of it for good.\n\nLets go to reddit and see what the inbox looks like.\n\n![](/assets/images/2020-10-11-18-22-29.png)\n\n\nWell, its just as we suspected, when we reply to a mention with the `comment` function it does not change the status of the message. Sifting through the [documentation](https://docs.rs/roux/1.0.0/roux/?search=read) of `roux` we can find a method that marks a message as `read`.\n\nThe place we are at right now reminds of a the poem [The Road Not Taken](https://www.poetryfoundation.org/poems/44272/the-road-not-taken) by Robert Frost. It talks about how the author finds two roads diverging in the wood and he ponders which one to travel upon. I ask you to take a few minutes and read the poem, its beautiful.\n\nI'll be waiting!\n\nOh BTW the code can be found on the `part-I` branch [here](https://github.com/DeltaManiac/VyomBot)\n\n# Part II\n\nIf you had read the poem mentioned in the previous part, you can be pretty sure what we are going to do right now. You Betcha! We are going to go down the Rabbit Hole.\n\nJust as in the poem it would have been easy for us to change the library to something that already has a `mark as read` method like many do and continue on, but like Frost we will take the road not taken and that might make all the difference. üòâ\n\n## Down the Rabbit Hole\n\nWe actually got stumped on the last part because there was no method to mark a message as read in `roux`. This makes one wonder if there isn't such an api for reddit or that `roux` just didn't implement it.\n\nLets head to [reddit api docs](https://www.reddit.com/dev/api) and try our luck.\n\nYep, reddit does have a [`read_message`](https://www.reddit.com/dev/api#POST_api_read_message) api for us to use exactly for this purpose. The api accepts a list of [fullnames](https://www.reddit.com/dev/api#fullnames) with an HTTP POST method.\n\nWhat is the `fullname` for our message ? Its nothing but the `name` parameter of the struct.\n\nNow to fix `roux`, so that we can mark the message as read.\n\nLets clone the [roux source code](https://github.com/halcyonnouveau/roux.rs) into another directory.\n\nSince the `comment` method we used is an api which POSTS the comment data to reddit. Perhaps we can ~~reuse~~, who are we kidding ? We can definitely _copy-paste_ and modify the code to send some data to the `read_message` api.\n\n> While searching for a way to mark a message as read, we came up across another api [`message/unread`](https://www.reddit.com/dev/api#GET_message_unread) which returns only the unread messages from our inbox, so we don't have to filter out on the `new` flag of the response anymore. Yay!\n\n```rust\n# src/me/mod.rs\n...\n/// Get user's submitted posts.\n    pub async fn inbox(&self) -> Result<BasicListing<InboxItem>, RouxError> {\n        Ok(self\n            .get(\"message/inbox\")\n            .await?\n            .json::<BasicListing<InboxItem>>()\n            .await?)\n    }\n\n/** This is our addition **/\n///  Get users unread messages\n    pub async fn unread(&self) -> Result<BasicListing<InboxItem>, RouxError> {\n        Ok(self\n            .get(\"message/unread\")\n            .await?\n            .json::<BasicListing<InboxItem>>()\n            .await?)\n    }\n\n/** This is our addition **/\n/// Mark message as read\n    pub async fn mark_read(&self, ids: &str) -> Result<Response, RouxError> {\n        let form = [(\"id\", ids)];\n        self.post(\"api/read_message\", &form).await\n    }\n\n/** This is our addition **/\n/// Mark messages as unread\n    pub async fn mark_read(&self, ids: &str) -> Result<Response, RouxError> {\n        let form = [(\"id\", ids)];\n        self.post(\"api/unread_message\", &form).await\n    }\n\n    pub async fn comment(&self, text: &str, parent: &str) -> Result<Response, RouxError> {\n        let form = [(\"text\", text), (\"parent\", parent)];\n        self.post(\"api/comment\", &form).await\n    }\n...\n```\n\n> I've submitted a [PR](https://github.com/halcyonnouveau/roux.rs/pull/13) to roux with these changes.\n\nSo all is good and well with the change, but how do we use this changed version with our code ?\n\n`Cargo.toml` is the answer. We can tell `Cargo.toml` to use the code from a directory or from a url for a specified crate. Since we have a the modified source code in our system, we can point to that to get it working.\n\n```toml\n# Cargo.toml\n\n[package]\nname = \"vyom\"\nversion = \"0.1.0\"\nauthors = [\"Harikrishnan Menon <harikrishnan.menon@sap.com>\"]\nedition = \"2018\"\n\n[dependencies]\nroux={path=\"../roux.rs\"} #This points to our local modified copy\n# roux={git = \"https://github.com/DeltaManiac/roux.rs\"} #This points to the modified version on github\ndotenv_codegen=\"0.15.0\"\ntokio = {version=\"0.2.22\", features=[\"macros\"]}\nenv_logger =\"0.7.1\"\nlog = \"0.4.11\"\n```\n\nWhen we build our project now, we can see that it picks up the roux source code from the new path specified by us.\n\n```shell\n(base) DeltaManiac @ ~/git/rust/vyom\n‚îî‚îÄ $ cargo build\n   Compiling roux v1.0.1-alpha.0 (/Users/DeltaManiac/git/rust/roux.rs)\n   Compiling vyom v0.1.0 (/Users/DeltaManiac/git/rust/vyom)\n   Finished dev [unoptimized + debuginfo] target(s) in 6.70s\n```\n\n> If we don't want go through the hassle of doing this, we can point cargo to my fork which has the necessary changes. This is how the code would be in the repository.\n\n## Actually Squashing the Bug\n\nNow that we are back from our exceedingly educating trip down the rabbit hole, lets see how we can finally mark a message as read after we reply to it.\n\n```rust\n# main.rs\n...\n...\n// Fetch only the unread messages form the inbox of the logged in user\nOk(client) => match client.unread().await {\n    Ok(listing) => {\n        for message in listing.data.children.iter() {\n            // We have removed the `new` check\n            if message.data.r#type == \"username_mention\" {\n                match client\n                    .comment(\n                        \"Thank you for standing by while we squished a bug. You shouldn't be seeing this message again!\",\n                        &message.data.name.as_str(),\n                    )\n                    .await\n                {\n                    Ok(_) => {\n                        info!(\"Replied to {}\", message.data.name);\n                        match client.mark_read(message.data.name.as_str()).await {\n                            Ok(_) => info!(\"Marked {} as read\", message.data.name),\n                            Err(_) => {\n                                error!(\"Failed to mark {} as read\", message.data.name)\n                            }\n                        }\n                    }\n                    Err(_) => error!(\"Failed to reply to mention {}\", message.data.name),\n                };\n            }\n        }\n    }\n...\n...\n```\n\nWe have changed the reply text so that we can identify from reddit that it is actually the new reply that is being sent, and we call the `mark_read` method form the modified crate to mark the message as read.\n\nLets run the code and see if it works. Fingers Crossed.\n\n```shell\n(base) DeltaManiac @ ~/git/rust/vyom\n‚îî‚îÄ $ cargo run\n   Compiling vyom v0.1.0\n    Finished dev [unoptimized + debuginfo] target(s) in 4.41s\n     Running `target/debug/vyom`\n[2020-08-09T16:38:11Z INFO  vyom] Replied to t1_g0vfbra\n[2020-08-09T16:38:11Z INFO  vyom] Marked t1_g0vfbra as read\n```\n\nCool, but does it actually mark the message as read? Lets run the program again a couple more times and figure it out.\n\n```shell\n(base) DeltaManiac @ ~/git/rust/vyom\n‚îî‚îÄ $ cargo run\n    Finished dev [unoptimized + debuginfo] target(s) in 0.10s\n     Running `target/debug/vyom`\n(base) DeltaManiac @ ~/git/rust/vyom\n‚îî‚îÄ $ cargo run\n    Finished dev [unoptimized + debuginfo] target(s) in 0.10s\n     Running `target/debug/vyom`\n(base) DeltaManiac @ ~/git/rust/vyom\n‚îî‚îÄ $\n```\n\nSince there doesn't seem to to be any logs being printed we can confirm that we are not replying again to the message. But it programming and you never know if you're right until you completely verify from reddit side too. Let go take a look at the subreddit.\n\n![](/assets/images/2020-10-11-18-24-11.png)\n\nYep, it has only one comment.\n\n## Extracting the Intel\n\nNow that we have figured out how to respond to comments, lets get to the actual crux of the problem.\n\nWhen a VyomBot gets mentioned where should he look for the Youtube link? There can be many answers to this question like\n\n1. The immediate parent comment of the mention\n2. The title of the post\n3. It could be part of the message sent to VyomBot\n\nThese all seem relevant, but to keep it simple lets start with 2, i.e if the parent is a YouTube playlist link then we fetch the information and post it as a comment.\n\nIn order to get the link of the playlist we are not going to use the roux library but instead handwrite it ourselves. Why you ask ? CAUSE ITS GONNA BE FUN!!\n\n> Note to reader the next part of the code is kind of hacky code and do not follow idiomatic rust. Here be Dragons üêâüêâüêâ\n\n### Constructing the Reddit Post link\n\nWe can use the `context` field of the response which looks like\n\n```json\n{\n...\n...\n    name: \"t1_g0vfbra\",\n    created: 1596987973.0,\n    created_utc: 1596959173.0,\n    context: \"/r/VyomBot/comments/i6fk15/test_playlist/g0vfbra/?context=3\",\n}\n```\n\nto construct the url of the post.\n\nThe first 5 parts `r`, `VyomBot`, `comments`, `i6fk15`, `test_playlist` can be used to for the url to the post.\nLet's do this right now.\n\n```rust\n# main.rs\n...\n if message.data.r#type == \"username_mention\" {\nlet post_url = format!(\n    \"https://www.reddit.com/{}/.json\",\n    message\n        .data\n        .context // /r/VyomBot/comments/i6fk15/test_playlist/g0vfbra/?context=3\n        .trim() // remove any trailing and leading spaces\n        .split('/') // [ \"\", \"r\", \"VyomBot\", \"comments\", \"i6fk15\", \"test_playlist\", \"g0vfbra\", \"?context=3\" ]\n        .skip(1) // [ \"r\", \"VyomBot\", \"comments\", \"i6fk15\", \"test_playlist\", \"g0vfbra\", \"?context=3\" ]\n        .collect::<Vec<&str>>()[0..=4] // Take the first 5 [ \"r\", \"VyomBot\", \"comments\", \"i6fk15\", \"test_playlist\" ]\n        .join(\"/\") // /r/VyomBot/comments/i6fk15/test_playlist/\n    );\n...\n```\n\nWe now have constructed the url `https://www.reddit.com/{}/r/VyomBot/comments/i6fk15/test_playlist/.json`. The `.json` at the end tells reddit to return the JSON formatted and not the HTML page of the post id specified\n\n### Extracting the Playlist ID\n\nIn order to query the url that we crafted above we would be using the [`reqwest`](https://crates.io/crates/reqwest) crate and the [`url`](https://crates.io/crates/url) crate. We fire a GET request to reddit and extract the `url` parameter from the response body which would have our link.\n\nWe then would convert the response body to a dynamic json using the [`serde_json`](https://crates.io/crates/serde_json) crate and then extract the link from the `url` property of the response.\n\nThen the [`url`](https://crates.io/crates/url) crate to parse and extract the playlist id from the YouTube link. For our link\n`https://www.youtube.com/playlist?list=PLf3u8NhoEikhTC5radGrmmqdkOK-xMDoZ` the playlist id is `PLf3u8NhoEikhTC5radGrmmqdkOK-xMDoZ`.\n\n```toml\n# Cargo.toml\n\n[package]\nname = \"vyom\"\nversion = \"0.1.0\"\nauthors = [\"Harikrishnan Menon <harikrishnan.menon@sap.com>\"]\nedition = \"2018\"\n\n[dependencies]\nroux={path=\"../roux.rs\"} #This points to our local modified copy\n# roux={git = \"https://github.com/DeltaManiac/roux.rs\"} #This points to the modified version on github\ndotenv_codegen=\"0.15.0\"\ntokio = {version=\"0.2.22\", features=[\"macros\"]}\nenv_logger =\"0.7.1\"\nlog = \"0.4.11\"\nreqwest = {version=\"0.10.7\",features=[\"json\"]} // New\nserde_json = \"1.0.57\" // New\nurl = \"2.1.1\"  // New\n\n```\n\n```rust\n# main.rs\n...\n...\n// Make an http request to the post url\nlet playlist_id = match reqwest::get(&post_url).await {\n    // If the response is received convert it in to dynamic json\n    Ok(response) => match response.json::<serde_json::Value>().await {\n        Ok(json) => {\n            // Get json[0][\"data\"][\"children][0][\"url}\n            // NB: DO NOT USE THIS CODE IN PRODUCTION\n            let url = match json\n                .get(0)\n                .unwrap()\n                .get(\"data\")\n                .unwrap()\n                .get(\"children\")\n                .unwrap()\n                .get(0)\n                .unwrap()\n                .get(\"data\")\n                .unwrap()\n                .get(\"url\")\n            {\n                // Parse the youtube url from the string\n                // \"https://www.youtube.com/playlist?list=PLf3u8NhoEikhTC5radGrmmqdkOK-xMDoZ\"\n                // after trimming `\"`\n                Some(url) => match url::Url::parse(\n                    &url.to_string().trim_matches('\\\"'),\n                ) {\n                    Ok(url) => {\n                        match (\n                            // From the query parameters\n                            // find the parameter with key \"list\"\n                            url.query_pairs().find(|q| {\n                                q.0 == \"list\"\n                            }),\n                            // Also check if the host is youtube\n                            (url.host_str() == Some(\"youtube.com\")\n                                || url.host_str()\n                                    == Some(\"www.youtube.com\")),\n                        ) {\n                            (Some((_, val)), true) => {\n                                // Return the url\n                                Some(val.into_owned())\n                            }\n                            (_, _) => {\n                                error!(\n                                    \"Couldn't find `list` param in url {} for message : {}\",\n                                    &url.to_string(),\n                                    &message.data.name\n                                );\n                                None\n                            }\n                        }\n                    }\n                    // Error Handling\n...\n\ndbg!(playlist_id);\n...\n...\n```\n\n> A better way to handle the response is to create a struct that mimics the response and just let the `.json()` method of reqwest do the heavy lifting of converting it into rust types. This will help avoid all the calls to `unwrap`.\n\n> The nested matches statements should be replaced by `.and_then()` for a more cleaner and readable code.\n\n```shell\n(base) DeltaManiac @ ~/git/rust/vyom\n‚îî‚îÄ $ cargo run\nCompiling vyom v0.1.0\nFinished dev [unoptimized + debuginfo] target(s) in 5.09s     Running `target/debug/vyom`\n[src/main.rs:200] \"playlist_id\" = \"PLf3u8NhoEikhTC5radGrmmqdkOK-xMDoZ\"\n[src/main.rs:200] \"playlist_id\" = \"PLf3u8NhoEikhTC5radGrmmqdkOK-xMDoZ\"\n```\n\nHooray! We've come a long way since we started, written some atrocious code, contributed to a library and even rolled out our own code instead of using library code to talk to talk to reddit.\n\nI know its getting boring now and we're gonna wrap it up in the next part.\n\nOh BTW the code can be found on the `part-II` branch [here](https://github.com/DeltaManiac/VyomBot)\n\n\n# Part III\n\nWe've reached the final chapter. The spoils are just ahead of us, lets go grab em.\n\n# Obtaining Credentials\n\nWe need to generate a different set of credentials to talk with YouTube. Lets go do that step by step..\n\n1. Logon to [Google Developer Console](https://console.developer.google.com)\n\n2. Click `Enable Apis and Service`\n    ![](/assets/images/2020-10-11-18-26-54.png)\n\n3. Search for `YouTube Data API v3`\n    ![](/assets/images/2020-10-11-18-27-09.png)\n\n4. Click the `Enable` button to enable the API for our account\n    ![](/assets/images/2020-10-11-18-27-17.png)\n\n5. Click the `Create Credentials` button to start creating credentials for us to use.\n    ![](/assets/images/2020-10-11-18-27-29.png)\n\n6. We need to first describe what kind of credentials have to be generated. Don't worry, just follow the screenshot.\n    ![](/assets/images/2020-10-11-18-27-39.png)\n\n7. We're Done!\n    ![](/assets/images/2020-10-11-18-27-51.png)\n\n\n# Handling JSON better\n\nIn the last part we used a dynamic JSON to to retrieve the playlist url from Reddit. This time to interact with the YouTube API we wont do that, instead we will one up ourselves and de-serialize the JSON into structs that we define in rust.\n\n> We use [`serde`](https://crates.io/crates/serde) to do handle the heavy lifting of JSON de-serialization\n\nThe response of the YouTube API is a bit more well defined than the Reddit API.\n\n```json\n{\n  \"kind\": \"youtube#playlistItemListResponse\",\n  \"etag\": \"Fij-lGuELswW5Y6HXEJsEVAZ6Xg\",\n  \"nextPageToken\": \"CAUQAA\",\n  \"items\": [\n    {\n      \"kind\": \"youtube#playlistItem\",\n      \"etag\": \"KC_3PIeEyspbfuA_AplI4dv2ITA\",\n      \"id\": \"UExmM3U4TmhvRWlraFRDNXJhZEdybW1xZGtPSy14TURvWi45ODRDNTg0QjA4NkFBNkQy\",\n      \"snippet\": {\n        \"publishedAt\": \"2020-08-05T19:31:06Z\",\n        \"channelId\": \"UC9X86dyEwpbCnpC18qjt33Q\",\n        \"title\": \"Rusty Days 2020 - Hackathon Submissions\",\n        \"description\": \"Rules ‚ñ∫ https://rusty-days.org/hackathon/\\n\\nTeams ‚ñ∫\\narrugginiti https://github.com/Rust-Wroclaw/rd-hack-arrugginiti\\nBox-Team https://github.com/Rust-Wroclaw/rd-hack-Box-Team\\nBrighter3D https://github.com/Rust-Wroclaw/rd-hack-Brighter3D\\nhexyoungs https://github.com/Rust-Wroclaw/rd-hack-hexyoungs\\nLastMinute https://github.com/Rust-Wroclaw/rd-hack-LastMinute\\nplanters https://github.com/Rust-Wroclaw/rd-hack-planters\\n\\nFollow ‚ñ∫\\nFacebook: https://rusty-days.org/facebook\\nTwitch: https://rusty-days.org/twitch\\nTwitter: https://rusty-days.org/twitter\",\n        \"thumbnails\": {\n          \"default\": {\n            \"url\": \"https://i.ytimg.com/vi/QaCvUKrxNLI/default.jpg\",\n            \"width\": 120,\n            \"height\": 90\n          },\n          \"medium\": {\n            \"url\": \"https://i.ytimg.com/vi/QaCvUKrxNLI/mqdefault.jpg\",\n            \"width\": 320,\n            \"height\": 180\n          },\n          \"high\": {\n            \"url\": \"https://i.ytimg.com/vi/QaCvUKrxNLI/hqdefault.jpg\",\n            \"width\": 480,\n            \"height\": 360\n          },\n          \"standard\": {\n            \"url\": \"https://i.ytimg.com/vi/QaCvUKrxNLI/sddefault.jpg\",\n            \"width\": 640,\n            \"height\": 480\n          }\n        },\n        \"channelTitle\": \"Rust Wroc≈Çaw\",\n        \"playlistId\": \"PLf3u8NhoEikhTC5radGrmmqdkOK-xMDoZ\",\n        \"position\": 0,\n        \"resourceId\": {\n          \"kind\": \"youtube#video\",\n          \"videoId\": \"QaCvUKrxNLI\"\n        }\n      }\n    },\n    {\n      \"kind\": \"youtube#playlistItem\",\n      \"etag\": \"EgGMmoAJ81l2BJFspcg1idaKy-8\",\n      \"id\": \"UExmM3U4TmhvRWlraFRDNXJhZEdybW1xZGtPSy14TURvWi5EMEEwRUY5M0RDRTU3NDJC\",\n      \"snippet\": {\n        \"publishedAt\": \"2020-08-01T12:17:09Z\",\n        \"channelId\": \"UC9X86dyEwpbCnpC18qjt33Q\",\n        \"title\": \"Rusty Days 2020 - Tim McNamara: How 10 open source projects manage unsafe code\",\n        \"description\": \"Agenda ‚ñ∫ https://rusty-days.org/agenda\\nSlides ‚ñ∫https://rusty-days.org/assets/slides/08-how-10-open-source-projects-manage-unsafe-code.pdf\\nPlaylist with all talks ‚ñ∫ https://www.youtube.com/playlist?list=PLf3u8NhoEikhTC5radGrmmqdkOK-xMDoZ\\n\\nFollow ‚ñ∫\\nFacebook: https://rusty-days.org/facebook\\nTwitch: https://rusty-days.org/twitch\\nTwitter: https://rusty-days.org/twitter\\n\\nThis video ‚ñ∫\\nIs it safe to use unsafe? Learn why some projects need unsafe code and how projects manage its risks.\\n\\nThis talk will briefly discuss what the unsafe keyword enables and what its risks are. The bulk of time will be spent discussing how projects manage those risks. It finishes by providing recommendations based on that analysis.\\n\\nProjects surveyed include:\\n* Servo (Mozilla)\\n* Fuchsia OS (Google)\\n* fast_rsync (Dropbox)\\n* winrt-rs (Microsoft)\\n* Firecracker (AWS)\\n* Linkerd2\",\n        \"thumbnails\": {\n          \"default\": {\n            \"url\": \"https://i.ytimg.com/vi/9M0NQI5Cp2c/default.jpg\",\n            \"width\": 120,\n            \"height\": 90\n          },\n          \"medium\": {\n            \"url\": \"https://i.ytimg.com/vi/9M0NQI5Cp2c/mqdefault.jpg\",\n            \"width\": 320,\n            \"height\": 180\n          },\n          \"high\": {\n            \"url\": \"https://i.ytimg.com/vi/9M0NQI5Cp2c/hqdefault.jpg\",\n            \"width\": 480,\n            \"height\": 360\n          },\n          \"standard\": {\n            \"url\": \"https://i.ytimg.com/vi/9M0NQI5Cp2c/sddefault.jpg\",\n            \"width\": 640,\n            \"height\": 480\n          },\n          \"maxres\": {\n            \"url\": \"https://i.ytimg.com/vi/9M0NQI5Cp2c/maxresdefault.jpg\",\n            \"width\": 1280,\n            \"height\": 720\n          }\n        },\n        \"channelTitle\": \"Rust Wroc≈Çaw\",\n        \"playlistId\": \"PLf3u8NhoEikhTC5radGrmmqdkOK-xMDoZ\",\n        \"position\": 1,\n        \"resourceId\": {\n          \"kind\": \"youtube#video\",\n          \"videoId\": \"9M0NQI5Cp2c\"\n        }\n      }\n    },\n    {\n      \"kind\": \"youtube#playlistItem\",\n      \"etag\": \"3gm-0cEUcjfm1v1vgh_3EjS6mJg\",\n      \"id\": \"UExmM3U4TmhvRWlraFRDNXJhZEdybW1xZGtPSy14TURvWi40NzZCMERDMjVEN0RFRThB\",\n      \"snippet\": {\n        \"publishedAt\": \"2020-08-01T12:16:07Z\",\n        \"channelId\": \"UC9X86dyEwpbCnpC18qjt33Q\",\n        \"title\": \"Rusty Days 2020 - Luca Palmieri: Are we observable yet?\",\n        \"description\": \"Agenda ‚ñ∫ https://rusty-days.org/agenda\\nSlides ‚ñ∫https://rusty-days.org/assets/slides/07-are-we-observable-yet.pdf\\nPlaylist with all talks ‚ñ∫ https://www.youtube.com/playlist?list=PLf3u8NhoEikhTC5radGrmmqdkOK-xMDoZ\\n\\nFollow ‚ñ∫\\nFacebook: https://rusty-days.org/facebook\\nTwitch: https://rusty-days.org/twitch\\nTwitter: https://rusty-days.org/twitter\\n\\nThis video ‚ñ∫\\nIs Rust ready for mainstream usage in backend development?\\n\\nThere is a lot of buzz around web frameworks while many other (critical!) Day 2 concerns do not get nearly as much attention.\\n\\nWe will discuss observability: do the tools currently available in the Rust ecosystem cover most of your telemetry needs?\\n\\nI will walk you through our journey here at TrueLayer when we built our first production backend system in Rust, Donate Direct.\\n\\nWe will be touching on the state of Rust tooling for logging, metrics and distributed tracing.\",\n        \"thumbnails\": {\n          \"default\": {\n            \"url\": \"https://i.ytimg.com/vi/HtKnLiFwHJM/default.jpg\",\n            \"width\": 120,\n            \"height\": 90\n          },\n          \"medium\": {\n            \"url\": \"https://i.ytimg.com/vi/HtKnLiFwHJM/mqdefault.jpg\",\n            \"width\": 320,\n            \"height\": 180\n          },\n          \"high\": {\n            \"url\": \"https://i.ytimg.com/vi/HtKnLiFwHJM/hqdefault.jpg\",\n            \"width\": 480,\n            \"height\": 360\n          },\n          \"standard\": {\n            \"url\": \"https://i.ytimg.com/vi/HtKnLiFwHJM/sddefault.jpg\",\n            \"width\": 640,\n            \"height\": 480\n          },\n          \"maxres\": {\n            \"url\": \"https://i.ytimg.com/vi/HtKnLiFwHJM/maxresdefault.jpg\",\n            \"width\": 1280,\n            \"height\": 720\n          }\n        },\n        \"channelTitle\": \"Rust Wroc≈Çaw\",\n        \"playlistId\": \"PLf3u8NhoEikhTC5radGrmmqdkOK-xMDoZ\",\n        \"position\": 2,\n        \"resourceId\": {\n          \"kind\": \"youtube#video\",\n          \"videoId\": \"HtKnLiFwHJM\"\n        }\n      }\n    },\n    {\n      \"kind\": \"youtube#playlistItem\",\n      \"etag\": \"2C9sX2xuTowOxjn0m95AH53JiA4\",\n      \"id\": \"UExmM3U4TmhvRWlraFRDNXJhZEdybW1xZGtPSy14TURvWi5GNjNDRDREMDQxOThCMDQ2\",\n      \"snippet\": {\n        \"publishedAt\": \"2020-07-31T11:28:34Z\",\n        \"channelId\": \"UC9X86dyEwpbCnpC18qjt33Q\",\n        \"title\": \"Rusty Days 2020 - Jan-Erik Rediger: Leveraging Rust to build cross-platform mobile libraries\",\n        \"description\": \"Agenda ‚ñ∫ https://rusty-days.org/agenda\\nSlides ‚ñ∫https://rusty-days.org/assets/slides/06-cross-platform-mobile-libraries.pdf\\nPlaylist with all talks ‚ñ∫ https://www.youtube.com/playlist?list=PLf3u8NhoEikhTC5radGrmmqdkOK-xMDoZ\\n\\nFollow ‚ñ∫\\nFacebook: https://rusty-days.org/facebook\\nTwitch: https://rusty-days.org/twitch\\nTwitter: https://rusty-days.org/twitter\\n\\n\\nThis video ‚ñ∫\\nAt Mozilla, Firefox is not the only product we ship. Many others ‚Äî including a variety of smartphone applications, and certainly not just web browsers ‚Äî are built by various teams across the organization. These applications are composed of a multitude of libraries which, when possible, are reused across platforms.\\n\\nIn the past year we used Rust to rebuild one of these libraries: the library powering the telemetry in our mobile applications is now integrated into Android and iOS applications and will soon be powering our Desktop platforms as well.\\n\\nThis talk will showcase how this small team managed to create a cross-platform Rust library, and ship it to a bunch of platforms all at once.\",\n        \"thumbnails\": {\n          \"default\": {\n            \"url\": \"https://i.ytimg.com/vi/j5rczOF7pzg/default.jpg\",\n            \"width\": 120,\n            \"height\": 90\n          },\n          \"medium\": {\n            \"url\": \"https://i.ytimg.com/vi/j5rczOF7pzg/mqdefault.jpg\",\n            \"width\": 320,\n            \"height\": 180\n          },\n          \"high\": {\n            \"url\": \"https://i.ytimg.com/vi/j5rczOF7pzg/hqdefault.jpg\",\n            \"width\": 480,\n            \"height\": 360\n          },\n          \"standard\": {\n            \"url\": \"https://i.ytimg.com/vi/j5rczOF7pzg/sddefault.jpg\",\n            \"width\": 640,\n            \"height\": 480\n          },\n          \"maxres\": {\n            \"url\": \"https://i.ytimg.com/vi/j5rczOF7pzg/maxresdefault.jpg\",\n            \"width\": 1280,\n            \"height\": 720\n          }\n        },\n        \"channelTitle\": \"Rust Wroc≈Çaw\",\n        \"playlistId\": \"PLf3u8NhoEikhTC5radGrmmqdkOK-xMDoZ\",\n        \"position\": 3,\n        \"resourceId\": {\n          \"kind\": \"youtube#video\",\n          \"videoId\": \"j5rczOF7pzg\"\n        }\n      }\n    },\n    {\n      \"kind\": \"youtube#playlistItem\",\n      \"etag\": \"pB_4gb7ai1HOgVLz8Jx9SJB1P_g\",\n      \"id\": \"UExmM3U4TmhvRWlraFRDNXJhZEdybW1xZGtPSy14TURvWi45NDk1REZENzhEMzU5MDQz\",\n      \"snippet\": {\n        \"publishedAt\": \"2020-07-31T09:06:09Z\",\n        \"channelId\": \"UC9X86dyEwpbCnpC18qjt33Q\",\n        \"title\": \"Rusty Days 2020 -  Nell Shamrell - Harrington: The Rust Borrow Checker - A Deep Dive\",\n        \"description\": \"Agenda ‚ñ∫ https://rusty-days.org/agenda\\nSlides ‚ñ∫https://rusty-days.org/assets/slides/05-the-rust-borrow-checker.pdf\\nPlaylist with all talks ‚ñ∫ https://www.youtube.com/playlist?list=PLf3u8NhoEikhTC5radGrmmqdkOK-xMDoZ\\n\\nFollow ‚ñ∫\\nFacebook: https://rusty-days.org/facebook\\nTwitch: https://rusty-days.org/twitch\\nTwitter: https://rusty-days.org/twitter\\n\\nThis video ‚ñ∫\\n\\nThe Rust compiler's borrow checker is critical for ensuring safe Rust code. Even more critical, however, is how the borrow checker provides useful, automated guidance on how to write safe code when the check fails. \\n\\nEarly in your Rust journey, it may feel like you are fighting the borrow checker. Come to this talk to learn how you can transition from fighting the borrow checker to using its guidance to write safer and more powerful code at any experience level. Walk away not only understanding the what and the how of the borrow checker - but why it works the way it does - and why it is so critical to both the technical functionality and philosophy of Rust.\",\n        \"thumbnails\": {\n          \"default\": {\n            \"url\": \"https://i.ytimg.com/vi/knhpe5IUnlE/default.jpg\",\n            \"width\": 120,\n            \"height\": 90\n          },\n          \"medium\": {\n            \"url\": \"https://i.ytimg.com/vi/knhpe5IUnlE/mqdefault.jpg\",\n            \"width\": 320,\n            \"height\": 180\n          },\n          \"high\": {\n            \"url\": \"https://i.ytimg.com/vi/knhpe5IUnlE/hqdefault.jpg\",\n            \"width\": 480,\n            \"height\": 360\n          },\n          \"standard\": {\n            \"url\": \"https://i.ytimg.com/vi/knhpe5IUnlE/sddefault.jpg\",\n            \"width\": 640,\n            \"height\": 480\n          },\n          \"maxres\": {\n            \"url\": \"https://i.ytimg.com/vi/knhpe5IUnlE/maxresdefault.jpg\",\n            \"width\": 1280,\n            \"height\": 720\n          }\n        },\n        \"channelTitle\": \"Rust Wroc≈Çaw\",\n        \"playlistId\": \"PLf3u8NhoEikhTC5radGrmmqdkOK-xMDoZ\",\n        \"position\": 4,\n        \"resourceId\": {\n          \"kind\": \"youtube#video\",\n          \"videoId\": \"knhpe5IUnlE\"\n        }\n      }\n    }\n  ],\n  \"pageInfo\": {\n    \"totalResults\": 9,\n    \"resultsPerPage\": 5\n  }\n}\n```\n\nThis JSON response can be constructed from simple structs that we can define.\nThe `#[derive(Deserialize)]` helps `serde` understand that it can use this struct to deserialize json into by matching the fields of the struct to those of that in the JSON body.\n\n> `serde` is an amazing library and a bit too vast to explain in this post.\n\n```rust\n# main.rs\n\n#[derive(Debug, Deserialize)]\nstruct Snippet {\n    title: String,\n    position: i32,\n}\n#[derive(Debug, Deserialize)]\nstruct Item {\n    kind: String,\n    snippet: Snippet,\n}\n#[derive(Debug, Deserialize)]\nstruct YoutubeResponse {\n    items: Vec<Item>,\n}\n```\n\nNow that we have defined our struct lets go ahead and call the YouTube API.\n\n```rust\n# main.rs\n\nlet mut reply: String =\n    \"Sorry couldn't find the YouTube Link! :(\".to_string();\n\nif playlist_id.is_some() {\n    // Generate api url\n    let url = format!(\"https://www.googleapis.com/youtube/v3/playlistItems?part=snippet&playlistId={}&key={}&maxResults={}\",playlist_id.unwrap(), YT_KEY, YT_MAX_RESULT);\n                        // Fire the API\n    let playlist_items = match reqwest::get(&url).await {\n                        // Try to convert the response to our struct\n        Ok(response) => match response.json::<YoutubeResponse>().await {\n            // Return the array of Item\n            Ok(yt_response) => Some(yt_response.items),\n            Err(e) => {\n                error!(\n                    \"Couldn't parse playlist response for comment {} reason : {}\",\n                        &message.data.name, e\n                            );\n                None\n            }\n        },\n        Err(e) => {\n            error!(\n                \"Couldn't fetch YouTube data for comment {} reason : {}\",\n                &message.data.name, e\n            );\n            None\n        }\n    };\n    //Loop over each item and then create the message.\n    if playlist_items.is_some() {\n        let items = playlist_items.unwrap();\n        if items.len() > 0 {\n            reply = \"Playlist Items: \\n\".to_string();\n            for item in items {\n                reply.push_str(\n                    format!(\"\\n {} \\n\", item.snippet.title).as_str(),\n                )\n            }\n        }\n    }\n}\n```\n\nWe first define `reply` with the string that we want to respond with if we fail to identify the playlist id.\nIf we have a playlistID we then call YouTube API with the key we generated earlier. We then extract the items of the playlist generated our reply text. The code that we have written in the previous part already handles replying to the message.\nLets try it out!\n\n```shell\n(base) DeltaManiac @ ~/git/rust/vyom\n‚îî‚îÄ $ cargo run\n   Compiling vyom v0.1.0\n    Finished dev [unoptimized + debuginfo] target(s) in 5.79s\n     Running `target/debug/vyom`\n[2020-08-11T18:46:46Z INFO  vyom] Replied to t1_g14nya9\n[2020-08-11T18:46:46Z INFO  vyom] Marked t1_g14nya9 as read\n```\n\nAnd on Reddit it looks just as beautiful!\n![](/assets/images/2020-10-11-18-30-04.png)\n\n# Fin\n\nThanks for joining along while we built our first bot :heart:.\nIf this journey has taught you something, feel free to give a shout out!\n","url":"https://deltamaniac.github.io/notes/ecfd8eb4-cdb2-459a-ab1e-8ced6abd9498.html","relUrl":"notes/ecfd8eb4-cdb2-459a-ab1e-8ced6abd9498.html"},{"doc":"Kafka","title":"Kafka","hpath":"kafka","content":"\n\n# Apache Kafka\n\n- pub-sub messaging system\n- basic unit --> message =>`{ Body :[u8], Key:[u8]}`\n- writes are mainly batch operations => `Vec<Messages>`\n- does not track acknowledgments from consumers but allows consumers to use Kafka to track their position (offset) in each partition.\n- Schema --> governs structure of message\n  - eg JSON/XML/[Apache Avro](https://avro.apache.org/docs/current/)\n- Topics --> collection of messages \"about something same\"\n- Topics made of n partitions => Append only queue-like\n    ![](/assets/images/2020-10-11-20-30-05.png)\n- Stream => Single topic of data irrespective of partitions\n\n- [[Producer|kafka.producer]]\n  - produce message for a topic, can sometimes specify which partition to store\n\n- [[Consumer|kafka.consumer]]\n  - Reads message\n  - Subscribes 1:n topics\n  - FIFO Read (Queue like)\n  - track of consumed messages via offset\n  - **Ownership** mapping of consumer to partitions\n- Consumer Group -> 1 or more consumers that work together to consumer a topic\n- Kafka Broker -> Single Kafka server\n  - Receives messages from Producers\n  - Assign offset\n  - Commit to disk\n- Kafka Cluster\n\n  - Collection of brokers\n  - **1** automatically elected broker will function as the cluster **controller**\n  - Controller responsibilities\n    - administrative operations\n    - assigning partitions to broker\n    - monitor for broker failures\n\n    ![](/assets/images/2020-10-11-20-31-20.png)\n\n- Retention -> Configurable for a period of time or size of topic (GB/MB)\n- Kafka : Pitch\n\n  - Multiple Producers x Multiple Topics\n  - Multiple Consumers\n  - Disk Based Retention --> No data loss\n  - Scalable\n  - High Performance\n\n## Starting Kafka on OSX\n\n```shell\n# Start ZooKeeper\n# `zkServer` DOESNT WORK IN TMUX!!!\nzookeeper-server-start /usr/local/etc/kafka/zookeeper.properties & kafka-server-start /usr/local/etc/kafka/server.properties\n\n# Start kafka server\nkafka-server-start.sh /usr/local/etc/kafka/server.properties\n\n# Create a topic\nkafka-topics --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic temptopic\n\n# Start a producer to temptopic\nkafka-console-producer --broker-list localhost:9092 --topic temptopic\n\n# In another tab start a consumer to temptopic\nkafka-console-producer --broker-list localhost:9092 --topic temptopic --from-beginning\n```\n","url":"https://deltamaniac.github.io/notes/bbb1f7dc-0a49-4a91-9578-9fff08abaaf8.html","relUrl":"notes/bbb1f7dc-0a49-4a91-9578-9fff08abaaf8.html"},{"doc":"Producer","title":"Producer","hpath":"kafka.producer","content":"\n# Producer\n\nKafka has a binary wire protocol.This means that it is possible for applications to read messages from Kafka or write messages to Kafka simply by sending the correct byte sequences to Kafka‚Äôs network port.\n\nKey Structure is `ProducerRecord`\n\n![](/assets/images/2020-10-11-20-37-00.png)\n\n# Serializer\n\nConverts between wire format and code\n\n[Apache Avro](https://https://avro.apache.org/docs/current)\nDefine a common schema for serialization and deserialization\nStore in schema Registry\nStore schema identifier in produced message\n![](/assets/images/2020-10-11-20-37-15.png)\n\n# Creating a Producer\n\n## In [[rust]]\n\nCrate : [kafka](https://crates.io/crates/kafka)\n\n```rust\n// Producer Code\nuse std::fmt::Write;\nuse std::time::Duration;\nuse kafka::producer::{Producer, Record, RequiredAcks};\n\nlet mut producer = Producer::from_hosts(vec!(\"localhost:9092\".to_owned()))\n.with_ack_timeout(Duration::from_secs(1))\n.with_required_acks(RequiredAcks::One)\n.create()\n.unwrap();\n\nlet mut buf = String::with*capacity(2);\nfor i in 0..10 {\nlet * = write!(&mut buf, \"{}\", i); // some computation of the message data to be sent\nproducer.send(&Record::from_value(\"my-topic\", buf.as_bytes())).unwrap();\nbuf.clear();\n}\n```\n\nCrate : [rdkafka](https://crates.io/crates/rdkafka)\n\n```rust\n sync fn produce(brokers: &str, topic_name: &str) {\n    let producer: &FutureProducer = &ClientConfig::new()\n        .set(\"bootstrap.servers\", brokers)\n        .set(\"message.timeout.ms\", \"5000\")\n        .create()\n        .expect(\"Producer creation error\");\n\n    // This loop is non blocking: all messages will be sent one after the other, without waiting\n    // for the results.\n    let futures = (0..5)\n        .map(|i| async move {\n            // The send operation on the topic returns a future, which will be\n            // completed once the result or failure from Kafka is received.\n            let delivery_status = producer\n                .send(\n                    FutureRecord::to(topic_name)\n                        .payload(&format!(\"Message {}\", i))\n                        .key(&format!(\"Key {}\", i))\n                        .headers(OwnedHeaders::new().add(\"header_key\", \"header_value\")),\n                    Duration::from_secs(0),\n                )\n                .await;\n\n            // This will be executed when the result is received.\n            info!(\"Delivery status for message {} received\", i);\n            delivery_status\n        })\n        .collect::<Vec<_>>();\n\n    // This loop will wait until all delivery statuses have been received.\n    for future in futures {\n        info!(\"Future completed. Result: {:?}\", future.await);\n    }\n}\n\n```\n\nSchema Registry for confluent : https://github.com/gklijs/schema_registry_converter\n\nConfluent Write up : https://www.confluent.io/blog/getting-started-with-rust-and-kafka/\n\n---\n\n## In [[go]]\n\nPackage : [Confluent Inc](https://github.com/confluentinc/confluent-kafka-go)\n\n```golang\nfunc main() {\n\n\tp, err := kafka.NewProducer(&kafka.ConfigMap{\"bootstrap.servers\": \"localhost\"})\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tdefer p.Close()\n\n\t// Delivery report handler for produced messages\n\tgo func() {\n\t\tfor e := range p.Events() {\n\t\t\tswitch ev := e.(type) {\n\t\t\tcase *kafka.Message:\n\t\t\t\tif ev.TopicPartition.Error != nil {\n\t\t\t\t\tfmt.Printf(\"Delivery failed: %v\\n\", ev.TopicPartition)\n\t\t\t\t} else {\n\t\t\t\t\tfmt.Printf(\"Delivered message to %v\\n\", ev.TopicPartition)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\n\t// Produce messages to topic (asynchronously)\n\ttopic := \"myTopic\"\n\tfor _, word := range []string{\"Welcome\", \"to\", \"the\", \"Confluent\", \"Kafka\", \"Golang\", \"client\"} {\n\t\tp.Produce(&kafka.Message{\n\t\t\tTopicPartition: kafka.TopicPartition{Topic: &topic, Partition: kafka.PartitionAny},\n\t\t\tValue:          []byte(word),\n\t\t}, nil)\n\t}\n\n\t// Wait for message deliveries before shutting down\n\tp.Flush(15 * 1000)\n}\n```\n\nPackage : [SegmentIO](https://github.com/segmentio/kafka-go)\n\n```golang\nfunc producer() {\n\n    topic := \"my-topic\"\n    partition := 0\n\n    conn, _ := kafka.DialLeader(context.Background(), \"tcp\", \"localhost:9092\", topic, partition)\n\n    conn.SetWriteDeadline(time.Now().Add(10*time.Second))\n    conn.WriteMessages(\n    kafka.Message{Value: []byte(\"one!\")},\n    kafka.Message{Value: []byte(\"two!\")},\n    kafka.Message{Value: []byte(\"three!\")},\n    )\n\n    conn.Close()\n}\n```\n\nPackage : [Sarama](https://github.com/Shopify/sarama)\n\n```golang\n//Sync Producer\nfunc newDataCollector(brokerList []string) sarama.SyncProducer {\n\n\t// For the data collector, we are looking for strong consistency semantics.\n\t// Because we don't change the flush settings, sarama will try to produce messages\n\t// as fast as possible to keep latency low.\n\tconfig := sarama.NewConfig()\n\tconfig.Producer.RequiredAcks = sarama.WaitForAll // Wait for all in-sync replicas to ack the message\n\tconfig.Producer.Retry.Max = 10                   // Retry up to 10 times to produce the message\n\tconfig.Producer.Return.Successes = true\n\ttlsConfig := createTlsConfiguration()\n\tif tlsConfig != nil {\n\t\tconfig.Net.TLS.Config = tlsConfig\n\t\tconfig.Net.TLS.Enable = true\n\t}\n\n\t// On the broker side, you may want to change the following settings to get\n\t// stronger consistency guarantees:\n\t// - For your broker, set `unclean.leader.election.enable` to false\n\t// - For the topic, you could increase `min.insync.replicas`.\n\n\tproducer, err := sarama.NewSyncProducer(brokerList, config)\n\tif err != nil {\n\t\tlog.Fatalln(\"Failed to start Sarama producer:\", err)\n\t}\n\n\treturn producer\n}\n\n// Async Producer\nfunc newAccessLogProducer(brokerList []string) sarama.AsyncProducer {\n\n\t// For the access log, we are looking for AP semantics, with high throughput.\n\t// By creating batches of compressed messages, we reduce network I/O at a cost of more latency.\n\tconfig := sarama.NewConfig()\n\ttlsConfig := createTlsConfiguration()\n\tif tlsConfig != nil {\n\t\tconfig.Net.TLS.Enable = true\n\t\tconfig.Net.TLS.Config = tlsConfig\n\t}\n\tconfig.Producer.RequiredAcks = sarama.WaitForLocal       // Only wait for the leader to ack\n\tconfig.Producer.Compression = sarama.CompressionSnappy   // Compress messages\n\tconfig.Producer.Flush.Frequency = 500 * time.Millisecond // Flush batches every 500ms\n\n\tproducer, err := sarama.NewAsyncProducer(brokerList, config)\n\tif err != nil {\n\t\tlog.Fatalln(\"Failed to start Sarama producer:\", err)\n\t}\n\n\t// We will just log to STDOUT if we're not able to produce messages.\n\t// Note: messages will only be returned here after all retry attempts are exhausted.\n\tgo func() {\n\t\tfor err := range producer.Errors() {\n\t\t\tlog.Println(\"Failed to write access log entry:\", err)\n\t\t}\n\t}()\n\n\treturn producer\n}\n\ngo func sendMessage(){\n        // Synch\n\t\tpartition, offset, err := s.DataCollector.SendMessage(&sarama.ProducerMessage{\n\t\t\tTopic: \"important\",\n\t\t\tValue: sarama.StringEncoder(r.URL.RawQuery),\n        })\n        // Async\n        s.AccessLogProducer.Input() <- &sarama.ProducerMessage{\n\t\t\tTopic: \"access_log\",\n\t\t\tKey:   sarama.StringEncoder(r.RemoteAddr),\n\t\t\tValue: entry,\n\t\t}\n}\n```\n","url":"https://deltamaniac.github.io/notes/b7749cd1-50ef-4a06-9ff3-08fec8a8c80a.html","relUrl":"notes/b7749cd1-50ef-4a06-9ff3-08fec8a8c80a.html"},{"doc":"Consumer","title":"Consumer","hpath":"kafka.consumer","content":"\n\n# Consumer\n\n- Subscribes to topics and receives message\n- Consumer Group -> method of scaling consumption\n\n  - Membership triggered by a `JoinGroup` call\n  - First member is the de-facto group leader\n  - leader assigns partitions to consumers in the consumer group\n  - Membership is maintained by sending _heartbeats_ at intervals regularly to the _group coordinator_\n  - Sent during `poll` and `commit`\n  - missing heartbeats for a period will trigger rebalance as the consumer is thought to be dead\n\n- _Rebalance_ moving partition ownership from one consumer to another\n  - high scalability and availability\n  - creates a short unavailability window\n\n![](/assets/images/2020-10-11-20-47-04.png)\n\n# Creating a Consumer\n\n## In [[Rust | rust]]\n\nCrate : [kafka](https://crates.io/crates/kafka)\n\n```rust\nuse kafka::consumer::{Consumer, FetchOffset, GroupOffsetStorage};\nlet mut consumer =\n   Consumer::from_hosts(vec!(\"localhost:9092\".to_owned()))\n      .with_topic_partitions(\"my-topic\".to_owned(), &[0, 1])\n      .with_fallback_offset(FetchOffset::Earliest)\n      .with_group(\"my-group\".to_owned())\n      .with_offset_storage(GroupOffsetStorage::Kafka)\n      .create()\n      .unwrap();\nloop {\n  for ms in consumer.poll().unwrap().iter() {\n    for m in ms.messages() {\n      println!(\"{:?}\", m);\n    }\n    consumer.consume_messageset(ms);\n  }\n  consumer.commit_consumed().unwrap();\n}\n```\n\nCrate : [rdkafka](https://crates.io/crates/rdkafka)\n\n```rust\nasync fn consume(brokers: &str, group_id: &str, topics: &[&str]) {\n    let context = CustomContext;\n\n    let consumer: LoggingConsumer = ClientConfig::new()\n        .set(\"group.id\", group_id)\n        .set(\"bootstrap.servers\", brokers)\n        .set(\"enable.partition.eof\", \"false\")\n        .set(\"session.timeout.ms\", \"6000\")\n        .set(\"enable.auto.commit\", \"true\")\n        //.set(\"statistics.interval.ms\", \"30000\")\n        //.set(\"auto.offset.reset\", \"smallest\")\n        .set_log_level(RDKafkaLogLevel::Debug)\n        .create_with_context(context)\n        .expect(\"Consumer creation failed\");\n\n    consumer\n        .subscribe(&topics.to_vec())\n        .expect(\"Can't subscribe to specified topics\");\n\n    // consumer.start() returns a stream. The stream can be used ot chain together expensive steps,\n    // such as complex computations on a thread pool or asynchronous IO.\n    let mut message_stream = consumer.start();\n\n    while let Some(message) = message_stream.next().await {\n        match message {\n            Err(e) => warn!(\"Kafka error: {}\", e),\n            Ok(m) => {\n                let payload = match m.payload_view::<str>() {\n                    None => \"\",\n                    Some(Ok(s)) => s,\n                    Some(Err(e)) => {\n                        warn!(\"Error while deserializing message payload: {:?}\", e);\n                        \"\"\n                    }\n                };\n                info!(\"key: '{:?}', payload: '{}', topic: {}, partition: {}, offset: {}, timestamp: {:?}\",\n                      m.key(), payload, m.topic(), m.partition(), m.offset(), m.timestamp());\n                if let Some(headers) = m.headers() {\n                    for i in 0..headers.count() {\n                        let header = headers.get(i).unwrap();\n                        info!(\"  Header {:#?}: {:?}\", header.0, header.1);\n                    }\n                }\n                consumer.commit_message(&m, CommitMode::Async).unwrap();\n            }\n        };\n    }\n}\n```\n\n---\n\n## In [[go]]\n\nPackage : [Confluent Inc](https://github.com/confluentinc/confluent-kafka-go)\n\n```golang\nfunc main() {\n\n\tc, err := kafka.NewConsumer(&kafka.ConfigMap{\n\t\t\"bootstrap.servers\": \"localhost\",\n\t\t\"group.id\":          \"myGroup\",\n\t\t\"auto.offset.reset\": \"earliest\",\n\t})\n\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tc.SubscribeTopics([]string{\"myTopic\", \"^aRegex.*[Tt]opic\"}, nil)\n\n\tfor {\n\t\tmsg, err := c.ReadMessage(-1)\n\t\tif err == nil {\n\t\t\tfmt.Printf(\"Message on %s: %s\\n\", msg.TopicPartition, string(msg.Value))\n\t\t} else {\n\t\t\t// The client will automatically try to recover from all errors.\n\t\t\tfmt.Printf(\"Consumer error: %v (%v)\\n\", err, msg)\n\t\t}\n\t}\n\n\tc.Close()\n}\n```\n\n## Package : [SegmentIO](https://github.com/segmentio/kafka-go)\n\n```golang\nfunc consumer(){\n  r := kafka.NewReader(kafka.ReaderConfig{\n      Brokers:   []string{\"localhost:9092\"},\n      Topic:     \"topic-A\",\n      Partition: 0,\n      MinBytes:  10e3, // 10KB\n      MaxBytes:  10e6, // 10MB\n  })\n  r.SetOffset(42)\n\n  for {\n      m, err := r.ReadMessage(context.Background())\n      if err != nil {\n          break\n      }\n      fmt.Printf(\"message at offset %d: %s = %s\\n\", m.Offset, string(m.Key), string(m.Value))\n  }\n\n  r.Close()\n}\n```\n\nPackage : [Sarama](https://github.com/Shopify/sarama)\n\n```golang\n// ConsumeClaim must start a consumer loop of ConsumerGroupClaim's Messages().\nfunc (consumer *Consumer) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error {\n\n\t// NOTE:\n\t// Do not move the code below to a goroutine.\n\t// The `ConsumeClaim` itself is called within a goroutine, see:\n\t// https://github.com/Shopify/sarama/blob/master/consumer_group.go#L27-L29\n\tfor message := range claim.Messages() {\n\t\tlog.Printf(\"Message claimed: value = %s, timestamp = %v, topic = %s\", string(message.Value), message.Timestamp, message.Topic)\n\t\tsession.MarkMessage(message, \"\")\n\t}\n\n\treturn nil\n}\n\ngo func() comsumer{\n\t\tdefer wg.Done()\n\t\tfor {\n\t\t\t// `Consume` should be called inside an infinite loop, when a\n\t\t\t// server-side rebalance happens, the consumer session will need to be\n\t\t\t// recreated to get the new claims\n\t\t\tif err := client.Consume(ctx, strings.Split(topics, \",\"), &consumer); err != nil {\n\t\t\t\tlog.Panicf(\"Error from consumer: %v\", err)\n\t\t\t}\n\t\t\t// check if context was cancelled, signaling that the consumer should stop\n\t\t\tif ctx.Err() != nil {\n\t\t\t\treturn\n\t\t\t}\n\t\t\tconsumer.ready = make(chan bool)\n\t\t}\n\t}()\n\n```\n\n# Commits\n\n- Consumers use kafka to track their position in each partition\n- `commit` act of updating current position in kafka\n- message `__consumer_offsets` topic with the offset for each partition\n- when rebalance each consumer receives a new partition and obtains the latest committed offset from where to start reading\n- Commit Strategy\n\n  - Automatic\n\n    - Done by consumer every 5 seconds configurable\n    - Commits largest offset from `poll`\n    - call to `poll` will always commit the last offset\n    - results in double processing if `rebalance` occurs in between a 5 sec window\n\n  - Commit Current Offset\n\n    - Gives control to the developer\n    - `commitSync` triggers commit of the last offset returned by `poll`\n    - must be called after processing all messages\n    - Synchronous call blocks the application\n    - Auto retry till success of non retry-able failure\n\n  - Asynchronous Commit\n\n    - Fire and forget till we get a callback\n    - Does not auto retry as a later commit request might have latest Offset\n\n  - Async + Sync Commit\n\n    - `CommitAsync` always\n    - Trigger a CommitSync just before exit\n","url":"https://deltamaniac.github.io/notes/21de6682-6669-43c0-8d66-68ceb823205d.html","relUrl":"notes/21de6682-6669-43c0-8d66-68ceb823205d.html"},{"doc":"Go","title":"Go","hpath":"go","content":"# Go\n\n## Kafka\n\n[[Producer | kafka.producer]]\n\n\n[[Consumer | kafka.consumer]]\n","url":"https://deltamaniac.github.io/notes/72f47187-278f-4a21-a56f-4abda62fea03.html","relUrl":"notes/72f47187-278f-4a21-a56f-4abda62fea03.html"},{"doc":"Framework","title":"Framework","hpath":"go.framework","content":"\n","url":"https://deltamaniac.github.io/notes/8e750d99-269a-4d2c-ba5d-35903d2b04c9.html","relUrl":"notes/8e750d99-269a-4d2c-ba5d-35903d2b04c9.html"},{"doc":"Gokit","title":"Gokit","hpath":"go.framework.gokit","content":"\n\n# Gokit\n\nSpring boot like framework for [[go]]. It has 3 major Components\n\n## Service Layer\n\n- Innermost layer where business logic resides.\n- Modeled as services\n- Oblivious to Endpoint/Transport Layers\n- Can be used by multiple Transports (grpc/json/http)\n\n## Endpoint Layer\n\n- Represents a single RPC Method\n- Service exposed as an Endpoint\n- Endpoint can be exposed by multiple Transports\n\n## Transport Layer\n\n- Exposes various Transports\n  - grpc\n  - http\n\n# Building a `pastebin` clone\n\n## Define a service blueprint interface\n\n```go\n// PbService provides storage capabilities\ntype PbService interface {\n\tCreate(content string, ctx context.Context) (string, error)\n\tDelete(key string, ctx context.Context) (string, error)\n\tGet(key string, ctx context.Context) (string, error)\n}\n```\n\n## Make a new struct to define the PasteBin Service\n\nThis struct is used to group together the functionalities of pastebin service\n\n```go\ntype pbService struct {\n\tmemory map[uuid.UUID]string\n}\n\n// NewPbService make a new PbService\nfunc NewPbService() PbService {\n\treturn pbService{\n\t\tmemory: make(map[uuid.UUID]string),\n\t}\n}\n```\n\n## Implement the PbService Interface on the struct\n\nIn [[go]] we do not have a key word to define that this structs implements a specific interface like the `implements` in Java.\n\nThey way we enforce contracts is by implementing all the methods of the contract interface in our case here its the `PbService` interface.\n\nSince our `NewPbService` method returns the type of `PbService` the go compiler will ensure that `NewPbService` confirms to the `PbService` interface.\n\n```go\n//Create: Here we store the content and return a uuid\nfunc (s pbService) Create(ctx context.Context, content string) (string, error) {\n\tid := uuid.New()\n\ts.memory[id] = content\n\treturn id.String(), nil\n}\n\n//Delete: Here we use the key to find and delete the content stored\nfunc (s pbService) Delete(ctx context.Context, key string) (string, error) {\n\tid, err := uuid.Parse(key)\n\tif err != nil {\n\t\treturn \"\", errors.New(\"Invalid Uuid Format\")\n\t}\n\tdelete(s.memory, id)\n\treturn \"ok\", nil\n}\n\n//Get: Here we use the key to find and return the content stored\nfunc (s pbService) Get(ctx context.Context, key string) (string, error) {\n\tid, err := uuid.Parse(key)\n\tif err != nil {\n\t\treturn \"\", errors.New(\"Invalid Uuid Format\")\n\t}\n\tcontent, exists := s.memory[id]\n\tif exists {\n\t\treturn content, nil\n\t}\n\treturn \"\", errors.New(\"Invalid Uuid\")\n}\n```\n\n## Request and Response\n\nIn Go kit, the primary messaging pattern is RPC.\n\nSo, every method in our interface will be modeled as a remote procedure call. For each method, we define request and response structs, capturing all of the input and output parameters respectively.\n\n### Create Request Response\n\n```go\ntype createPbRequest struct {\n\tcontent string `json:\"content\"`\n}\n\ntype createPbResponse struct {\n\tkey string `json:\"key\"`\n\tErr string `json:\"err,omitempty\"` // errors don't JSON-marshal, so we use a string\n}\n```\n\n### Delete Request Response\n\n```go\ntype deletePbRequest struct {\n\tkey string `json:\"key\"`\n}\n\ntype deletePbResponse struct {\n\tstatus string `json:\"status\"`\n\tErr    string `json:\"err,omitempty\"` // errors don't JSON-marshal, so we use a string\n}\n```\n\n### Get Request Response\n\n```go\ntype getPbRequest struct {\n\tkey string `json:\"key\"`\n}\n\ntype getPbResponse struct {\n\tcontent string `json:\"content\"`\n\tErr     string `json:\"err,omitempty\"` // errors don't JSON-marshal, so we use a string\n}\n```\n\n## Define Endpoints\n\nAn endpoint represents a single RPC, which is a single method in our service.\n\n### Create Endpoint\n\n```go\nfunc createPbEndpoint(svc PbService) endpoint.Endpoint {\n\treturn func(ctx context.Context, request interface{}) (interface{}, error) {\n\t\treq := request.(createPbRequest)\n\t\tkey, err := svc.Create(ctx, req.Content)\n\t\tif err != nil {\n\t\t\treturn createPbResponse{key, err.Error()}, nil\n\t\t}\n\t\treturn createPbResponse{key, \"\"}, nil\n\t}\n}\n```\n\n### Delete Endpoint\n\n```go\nfunc deletePbEndpoint(svc PbService) endpoint.Endpoint {\n\treturn func(ctx context.Context, request interface{}) (interface{}, error) {\n\t\treq := request.(deletePbRequest)\n\t\tstatus, err := svc.Delete(ctx, req.Key)\n\t\tif err != nil {\n\t\t\treturn deletePbResponse{status, err.Error()}, nil\n\t\t}\n\t\treturn deletePbResponse{status, \"\"}, nil\n\t}\n}\n```\n\n### Get Endpoint\n\n```go\nfunc getPbEndpoint(svc PbService) endpoint.Endpoint {\n\treturn func(ctx context.Context, request interface{}) (interface{}, error) {\n\t\treq := request.(getPbRequest)\n\t\tcontent, err := svc.Get(ctx, req.Key)\n\t\tif err != nil {\n\t\t\treturn getPbResponse{content, err.Error()}, nil\n\t\t}\n\t\treturn getPbResponse{content, \"\"}, nil\n\t}\n}\n```\n## Define Transport\n\nSince this trivial example used JSON over HTTP we would have to decode the JSON to structs that our service can understand\n\n### Create Requester Decoder\n\n```go\nfunc decodeCreatePbRequest(_ context.Context, r *http.Request) (interface{}, error) {\n\tvar request createPbRequest\n\tif err := json.NewDecoder(r.Body).Decode(&request); err != nil {\n\t\treturn nil, err\n\t}\n\treturn request, nil\n}\n```\n\n### Delete Request Decoder\n\n```go\nfunc decodeDeletePbRequest(_ context.Context, r *http.Request) (interface{}, error) {\n\tvar request deletePbRequest\n\tif err := json.NewDecoder(r.Body).Decode(&request); err != nil {\n\t\treturn nil, err\n\t}\n\treturn request, nil\n}\n```\n\n### Get Request Decoder\n\n```go\nfunc decodeGetPbRequest(_ context.Context, r *http.Request) (interface{}, error) {\n\tvar request getPbRequest\n\tif err := json.NewDecoder(r.Body).Decode(&request); err != nil {\n\t\treturn nil, err\n\t}\n\treturn request, nil\n}\n```\n### Response Encoder\n\nThis method would accept an `interface` type and convert it JSON, this allows it to accept `createPbResponse`,`deletePbResponse`,`getPbResponse` as an `interface{}` and encode it as json using the annotations in the struct definition.\n\n```go\nfunc encodeResponse(_ context.Context, w http.ResponseWriter, response interface{}) error {\n\treturn json.NewEncoder(w).Encode(response)\n}\n```\n\n## Main\n\n```go\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"log\"\n\t\"net/http\"\n\n\t\"github.com/go-kit/kit/endpoint\"\n\t\"github.com/google/uuid\"\n\n\thttptransport \"github.com/go-kit/kit/transport/http\"\n)\n\nfunc main() {\n\tsvc := NewPbService()\n\tcreatePbHandler := httptransport.NewServer(\n\t\tcreatePbEndpoint(svc),\n\t\tdecodeCreatePbRequest,\n\t\tencodeResponse,\n\t)\n\n\tdeletePbHandler := httptransport.NewServer(\n\t\tdeletePbEndpoint(svc),\n\t\tdecodeDeletePbRequest,\n\t\tencodeResponse,\n\t)\n\n\tgetPbHandler := httptransport.NewServer(\n\t\tgetPbEndpoint(svc),\n\t\tdecodeGetPbRequest,\n\t\tencodeResponse,\n\t)\n\n\thttp.Handle(\"/create\", createPbHandler)\n\thttp.Handle(\"/delete\", deletePbHandler)\n\thttp.Handle(\"/get\", getPbHandler)\n\tlog.Fatal(http.ListenAndServe(\":8080\", nil))\n}\n```\n## Divide and Conquer\nAt this point the `main.go` has a lot of code so lets move to different files so that we have separation of concerns.\n\n### `service.go`\n\n```go\npackage main\n\nimport (\n\t\"context\"\n\t\"errors\"\n\n\t\"github.com/google/uuid\"\n)\n\n// PbService provides storage capabilities\ntype PbService interface {\n\tCreate(ctx context.Context, content string) (string, error)\n\tDelete(ctx context.Context, key string) (string, error)\n\tGet(ctx context.Context, key string) (string, error)\n}\n\ntype pbService struct {\n\tmemory map[uuid.UUID]string\n}\n\n// NewPbService make a new PbService\nfunc NewPbService() PbService {\n\treturn pbService{\n\t\tmemory: make(map[uuid.UUID]string),\n\t}\n}\n\n//Create: Here we store the content and return a uuid\nfunc (s pbService) Create(ctx context.Context, content string) (string, error) {\n\tid := uuid.New()\n\ts.memory[id] = content\n\treturn id.String(), nil\n}\n\n//Get: Here we use the key to find and return the content stored\nfunc (s pbService) Get(ctx context.Context, key string) (string, error) {\n\tid, err := uuid.Parse(key)\n\tif err != nil {\n\t\treturn \"\", errors.New(\"Invalid Uuid Format\")\n\t}\n\tcontent, exists := s.memory[id]\n\tif exists {\n\t\treturn content, nil\n\t}\n\treturn \"\", errors.New(\"Invalid Uuid\")\n}\n\n//Delete: Here we use the key to find and delete the content stored\nfunc (s pbService) Delete(ctx context.Context, key string) (string, error) {\n\tid, err := uuid.Parse(key)\n\tif err != nil {\n\t\treturn \"\", errors.New(\"Invalid Uuid Format\")\n\t}\n\tdelete(s.memory, id)\n\treturn \"ok\", nil\n}\n```\n\n### `transport.go`\n\n```go\npackage main\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"net/http\"\n\n\t\"github.com/go-kit/kit/endpoint\"\n)\n\ntype createPbRequest struct {\n\tContent string `json:\"content\"`\n}\n\ntype createPbResponse struct {\n\tKey string `json:\"key\"`\n\tErr string `json:\"err,omitempty\"` // errors don't JSON-marshal, so we use a string\n}\n\ntype getPbRequest struct {\n\tKey string `json:\"key\"`\n}\n\ntype getPbResponse struct {\n\tContent string `json:\"content\"`\n\tErr     string `json:\"err,omitempty\"` // errors don't JSON-marshal, so we use a string\n}\n\ntype deletePbRequest struct {\n\tKey string `json:\"key\"`\n}\n\ntype deletePbResponse struct {\n\tStatus string `json:\"status\"`\n\tErr    string `json:\"err,omitempty\"` // errors don't JSON-marshal, so we use a string\n}\n\nfunc createPbEndpoint(svc PbService) endpoint.Endpoint {\n\treturn func(ctx context.Context, request interface{}) (interface{}, error) {\n\t\treq := request.(createPbRequest)\n\t\tkey, err := svc.Create(ctx, req.Content)\n\t\tif err != nil {\n\t\t\treturn createPbResponse{key, err.Error()}, nil\n\t\t}\n\t\treturn createPbResponse{key, \"\"}, nil\n\t}\n}\n\nfunc deletePbEndpoint(svc PbService) endpoint.Endpoint {\n\treturn func(ctx context.Context, request interface{}) (interface{}, error) {\n\t\treq := request.(deletePbRequest)\n\t\tstatus, err := svc.Delete(ctx, req.Key)\n\t\tif err != nil {\n\t\t\treturn deletePbResponse{status, err.Error()}, nil\n\t\t}\n\t\treturn deletePbResponse{status, \"\"}, nil\n\t}\n}\n\nfunc getPbEndpoint(svc PbService) endpoint.Endpoint {\n\treturn func(ctx context.Context, request interface{}) (interface{}, error) {\n\t\treq := request.(getPbRequest)\n\t\tcontent, err := svc.Get(ctx, req.Key)\n\t\tif err != nil {\n\t\t\treturn getPbResponse{content, err.Error()}, nil\n\t\t}\n\t\treturn getPbResponse{content, \"\"}, nil\n\t}\n}\n\nfunc decodeCreatePbRequest(_ context.Context, r *http.Request) (interface{}, error) {\n\tvar request createPbRequest\n\tif err := json.NewDecoder(r.Body).Decode(&request); err != nil {\n\t\treturn nil, err\n\t}\n\treturn request, nil\n}\n\nfunc decodeGetPbRequest(_ context.Context, r *http.Request) (interface{}, error) {\n\tvar request getPbRequest\n\tif err := json.NewDecoder(r.Body).Decode(&request); err != nil {\n\t\treturn nil, err\n\t}\n\treturn request, nil\n}\n\nfunc decodeDeletePbRequest(_ context.Context, r *http.Request) (interface{}, error) {\n\tvar request deletePbRequest\n\tif err := json.NewDecoder(r.Body).Decode(&request); err != nil {\n\t\treturn nil, err\n\t}\n\treturn request, nil\n}\n```\n\n### `main.go`\n\n```go\nfunc main() {\n\tsvc := NewPbService()\n\tcreatePbHandler := httptransport.NewServer(\n\t\tcreatePbEndpoint(svc),\n\t\tdecodeCreatePbRequest,\n\t\tencodeResponse,\n\t)\n\n\tdeletePbHandler := httptransport.NewServer(\n\t\tdeletePbEndpoint(svc),\n\t\tdecodeDeletePbRequest,\n\t\tencodeResponse,\n\t)\n\tgetPbHandler := httptransport.NewServer(\n\t\tgetPbEndpoint(svc),\n\t\tdecodeGetPbRequest,\n\t\tencodeResponse,\n\t)\n\thttp.Handle(\"/create\", createPbHandler)\n\thttp.Handle(\"/delete\", deletePbHandler)\n\thttp.Handle(\"/get\", getPbHandler)\n\tlog.Fatal(http.ListenAndServe(\":8080\", nil))\n}\n```\n## Logging Middleware\n\nAll applications need to log information, this can be enabled by adding a logging middleware that we create in a file called `logging.go`\n\nMiddleware in go-kit work on `Endpoint`\n\nThe interface definition is `type Middleware func(Endpoint) Endpoint`, which means it is a function that takes in an endpoint and returns an endpoint\n\nWe can create the `loggingMiddleware` so that it adheres to the `PbService` by implementing the `Create` `Delete` `Get` methods.\n```go\ntype loggingMiddleware struct {\n\tlogger log.Logger\n\tnext   PbService\n}\n```\n\n### Create\n```go\nfunc (m loggingMiddleware) Create(ctx context.Context, content string) (output string, err error) {\n\t// This defered function would be invoked just before the retuen statement\n\tdefer func(begin time.Time) {\n\t\tm.logger.Log(\n\t\t\t\"method\", \"CreatePb\",\n\t\t\t\"input\", content,\n\t\t\t\"output\", output,\n\t\t\t\"err\", err,\n\t\t\t\"took\", time.Since(begin),\n\t\t)\n\t}(time.Now())\n\toutput, err = m.next.Create(ctx, content)\n\treturn\n}\n```\n\n### Delete\n```go\n func (m loggingMiddleware) Delete(ctx context.Context, key string) (output string, err error) {\n\tdefer func(begin time.Time) {\n\t\tm.logger.Log(\n\t\t\t\"method\", \"DeletePb\",\n\t\t\t\"input\", key,\n\t\t\t\"output\", output,\n\t\t\t\"err\", err,\n\t\t\t\"took\", time.Since(begin),\n\t\t)\n\t}(time.Now())\n\toutput, err = m.next.Delete(ctx, key)\n\treturn\n}\n```\n\n### Get\n```go\nfunc (m loggingMiddleware) Get(ctx context.Context, key string) (output string, err error) {\n\tdefer func(begin time.Time) {\n\t\tm.logger.Log(\n\t\t\t\"method\", \"GetPb\",\n\t\t\t\"input\", key,\n\t\t\t\"output\", output,\n\t\t\t\"err\", err,\n\t\t\t\"took\", time.Since(begin),\n\t\t)\n\t}(time.Now())\n\toutput, err = m.next.Get(ctx, key)\n\treturn\n}\n```\n\n## Wiring the Middleware\n\nIn order to wire the middleware in all we have to do is link it up with the service that we have defined\n\n```go\npackage main\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"net/http\"\n\t\"os\"\n\n\t\"github.com/go-kit/kit/log\"\n\n\thttptransport \"github.com/go-kit/kit/transport/http\"\n)\n\nfunc main() {\n\t// Use the global logger\n\tlogger := log.NewLogfmtLogger(os.Stderr)\n\tvar svc PbService\n\tsvc = NewPbService()\n\t// Wire the middleware and thats it\n\tsvc = loggingMiddleware{logger, svc}\n\n\tcreatePbHandler := httptransport.NewServer(\n\t\tcreatePbEndpoint(svc),\n\t\tdecodeCreatePbRequest,\n\t\tencodeResponse,\n\t)\n\n\tdeletePbHandler := httptransport.NewServer(\n\t\tdeletePbEndpoint(svc),\n\t\tdecodeDeletePbRequest,\n\t\tencodeResponse,\n\t)\n\n\tgetPbHandler := httptransport.NewServer(\n\t\tgetPbEndpoint(svc),\n\t\tdecodeGetPbRequest,\n\t\tencodeResponse,\n\t)\n\thttp.Handle(\"/create\", createPbHandler)\n\thttp.Handle(\"/delete\", deletePbHandler)\n\thttp.Handle(\"/get\", getPbHandler)\n\tlogger.Log(\"msg\", \"HTTP\", \"addr\", \":8080\")\n\tlogger.Log(\"err\", http.ListenAndServe(\":8080\", nil))\n}\n\nfunc encodeResponse(_ context.Context, w http.ResponseWriter, response interface{}) error {\n\treturn json.NewEncoder(w).Encode(response)\n}\n```\n\n## PasteBin\n### Client\n```sh\n\n$ curl localhost:8080/create -XPOST -d '{\"content\":\"THIS IS SPARTA\"}'\n\n{\"key\":\"c449250a-d74c-4d23-acbb-6785b0bd822a\"}\n\n$ curl localhost:8080/get -XPOST -d '{\"key\":\"c449250a-d74c-4d23-acbb-6785b0bd822a\"}'\n\n{\"content\":\"THIS IS SPARTA\"}\n\n$ curl localhost:8I00/delete -XPOST -d '{\"key\":\"c449250a-d74c-4d23-acbb-6785b0bd822a\"}'\n\n{\"status\":\"ok\"}\n\n$ curl localhost:8080/get -XPOST -d '{\"key\":\"c449250a-d74c-4d23-acbb-6785b0bd822a\"}'\n\n{\"content\":\"\",\"err\":\"Invalid Uuid\"}\n\n```\n\n### Server\n```sh\n$ ./pastebin-II\n\nmsg=HTTP addr=:8080\n\nmethod=CreatePb input=\"THIS IS SPARTA\" output=c449250a-d74c-4d23-acbb-6785b0bd822a err=null took=67.92¬µs\n\nmethod=GetPb input=c449250a-d74c-4d23-acbb-6785b0bd822a output=\"THIS IS SPARTA\" err=null took=1.675¬µs\n\nmethod=DeletePb input=c449250a-d74c-4d23-acbb-6785b0bd822a output=ok err=null took=1.45¬µs\n\nmethod=GetPb input=c449250a-d74c-4d23-acbb-6785b0bd822a output= err=\"Invalid Uuid\" took=803ns\n```\n","url":"https://deltamaniac.github.io/notes/8f8f58c7-8ffc-4b8b-98e9-c4e8eb563e70.html","relUrl":"notes/8f8f58c7-8ffc-4b8b-98e9-c4e8eb563e70.html"},{"doc":"Games","title":"Games","hpath":"games","content":"\n","url":"https://deltamaniac.github.io/notes/7f7613d7-a18e-4c9f-aac2-59a0c98561c3.html","relUrl":"notes/7f7613d7-a18e-4c9f-aac2-59a0c98561c3.html"},{"doc":"Tis-100","title":"Tis-100","hpath":"games.tis-100","content":"\n","url":"https://deltamaniac.github.io/notes/5c421f85-a4d9-4581-9b82-e1aebfb60420.html","relUrl":"notes/5c421f85-a4d9-4581-9b82-e1aebfb60420.html"},{"doc":"Segment","title":"Segment","hpath":"games.tis-100.segment","content":"\n","url":"https://deltamaniac.github.io/notes/773dd5dc-f267-4a01-bb29-e433bcabca8c.html","relUrl":"notes/773dd5dc-f267-4a01-bb29-e433bcabca8c.html"},{"doc":"31904","title":"31904","hpath":"games.tis-100.segment.31904","content":"\n# Sequence Counter\n\n# Solution\n\n```\n@0\n\n\n@1\nMOV UP ACC\nMOV ACC RIGHT\nMOV ACC DOWN\n\n@2\nSTART:\nMOV LEFT ACC\nJNZ ADD\nJMP TERMINATE\nADD:\nSWP\nADD 1\nSAV\nJMP START\nTERMINATE:\nSWP\nMOV ACC DOWN\nMOV 0 ACC\n\n@3\nMOV RIGHT ACC\nMOV ACC RIGHT\n\n@4\nSTART:\nMOV UP ACC\nJNZ ADD\nJMP TERMINATE\nADD:\nMOV ACC LEFT\nSWP\nADD LEFT\nSAV\nJMP START\nTERMINATE:\nSWP\nMOV ACC DOWN\nMOV 0 ACC\n\n@5\nMOV UP DOWN\n\n@6\n\n\n@7\n\n\n@8\nMOV UP DOWN\n\n@9\nMOV UP DOWN\n\n@10\n\n```\n\n# Solution\n\n![](/assets/images/2020-12-26-13-50-24.png)","url":"https://deltamaniac.github.io/notes/de4f35ff-985c-40fb-af0c-5c8440a6b73b.html","relUrl":"notes/de4f35ff-985c-40fb-af0c-5c8440a6b73b.html"},{"doc":"30647","title":"30647","hpath":"games.tis-100.segment.30647","content":"\n# Sequence Generator\n\n# Solution\n\n```\n@0\n\n\n@1\nMOV UP, ACC\nMOV ACC,RIGHT\nMOV ACC,DOWN\n\n@2\nMOV UP,ACC\nSAV\nSUB LEFT\nMOV ACC,DOWN\nSWP\nMOV ACC DOWN\n\n@3\n\n\n@4\n\n\n@5\nMOV UP,RIGHT\n\n@6\nSTART:\nMOV UP,ACC\nJLZ ACCEPT_TOP\n\nACCEPT_LEFT:\nMOV LEFT,DOWN\nMOV UP,DOWN\nJMP START\n\nACCEPT_TOP:\nMOV UP,DOWN\nMOV LEFT,DOWN\nJMP START\n\n@7\n\n\n@8\n\n\n@9\nMOV -2,ACC\nSTART:\nJEZ RESET\nMOV UP,DOWN\nADD 1\nJMP START\n\nRESET:\nMOV 0,DOWN\nMOV -2,ACC\nJMP START\n\n@10\n\n```\n\n# Solution\n\n![](/assets/images/2020-11-05-21-29-23.png)","url":"https://deltamaniac.github.io/notes/c6de8a46-6510-46dd-a8fd-9eac3b993fb3.html","relUrl":"notes/c6de8a46-6510-46dd-a8fd-9eac3b993fb3.html"},{"doc":"22280","title":"22280","hpath":"games.tis-100.segment.22280","content":"\n# Signal Multiplexer\n\n# Solution\n\n```\n@0\n\n\n@1\nMOV UP,DOWN\n\n@2\nMOV UP,DOWN\n\n@3\nMOV UP,DOWN\n\n@4\n\n\n@5\nMOV UP,RIGHT\n\n@6\nSTART:\nMOV UP,ACC\nJEZ READ_BOTH\nJGZ READ_RIGHT\nMOV RIGHT,ACC\nMOV LEFT,DOWN\nJMP START\nREAD_RIGHT:\nMOV LEFT,ACC\nMOV RIGHT,DOWN\nJMP START\nREAD_BOTH:\nMOV RIGHT,ACC\nADD LEFT\nMOV ACC,DOWN\n\n@7\nMOV UP,LEFT\n\n@8\n\n\n@9\nMOV UP,DOWN\n\n@10\n\n```\n\n# Solution\n![](/assets/images/2020-11-05-21-27-40.png)","url":"https://deltamaniac.github.io/notes/18792729-fd0e-457a-bb67-fd1cd7e1dcfc.html","relUrl":"notes/18792729-fd0e-457a-bb67-fd1cd7e1dcfc.html"},{"doc":"21340","title":"21340","hpath":"games.tis-100.segment.21340","content":"\n# Signal Comparator\n\n# Solution\n\n```\n@0\nMOV UP,DOWN\n\n@1\n\n\n@2\n\n\n@3\n\n\n@4\nMOV UP,DOWN\n\n@5\nMOV UP,RIGHT\n\n@6\nSTART:\nMOV LEFT,ACC\nJGZ WRITE1\nMOV ACC,RIGHT\nMOV 0,DOWN\nJMP START\n\n\nWRITE1:\nMOV ACC,RIGHT\nMOV 1,DOWN\nJMP START\n\n@7\nSTART:\nMOV LEFT,ACC\nJEZ WRITE1\nMOV ACC,RIGHT\nMOV 0,DOWN\nJMP START\n\n\nWRITE1:\nMOV ACC,RIGHT\nMOV 1,DOWN\nJMP START\n\n@8\nSTART:\nMOV LEFT,ACC\nJLZ WRITE1\nMOV 0,DOWN\nJMP START\n\n\nWRITE1:\nMOV 1,DOWN\nJMP START\n```\n\n# Solution\n\n![](/assets/images/2020-11-05-21-23-20.png)","url":"https://deltamaniac.github.io/notes/54c5c95f-6a43-444d-bca9-55842b793a8a.html","relUrl":"notes/54c5c95f-6a43-444d-bca9-55842b793a8a.html"},{"doc":"20176","title":"20176","hpath":"games.tis-100.segment.20176","content":"\n# Differential Converter\n\n# Solution\n\n```\n@0\n\n\n@1\nMOV UP,ACC\nMOV ACC,RIGHT\nSUB RIGHT\nMOV ACC,DOWN\n\n@2\nMOV UP,ACC\nSAV\nSUB LEFT\nMOV ACC,DOWN\nSWP\nMOV ACC,LEFT\n\n@3\n\n\n@4\n\n\n@5\nMOV UP,DOWN\n\n@6\nMOV UP,DOWN\n\n@7\n\n\n@8\nMOV UP,DOWN\n\n@9\nMOV UP,DOWN\n\n@10\n\n```\n\n# Solution\n\n![](/assets/images/2020-10-25-21-46-37.png)","url":"https://deltamaniac.github.io/notes/c2e71c4f-5214-4c80-a678-4e2f1cde11ad.html","relUrl":"notes/c2e71c4f-5214-4c80-a678-4e2f1cde11ad.html"},{"doc":"10981","title":"10981","hpath":"games.tis-100.segment.10981","content":"\n# Signal Amplifier\n\n# Solution\n\n```\n@0\n\n\n@1\nMOV UP,DOWN\n\n@2\n\n\n@3\n\n\n@4\nMOV UP,DOWN\n\n@5\n\n\n@6\n\n\n@7\nMOV UP,RIGHT\n\n@8\nMOV LEFT,ACC\nADD ACC\nMOV ACC,DOWN\n\n@9\n```\n\n# Solution\n![](/assets/images/2020-10-25-21-46-17.png)","url":"https://deltamaniac.github.io/notes/70899221-a056-4a90-bd18-eb70f749b27b.html","relUrl":"notes/70899221-a056-4a90-bd18-eb70f749b27b.html"},{"doc":"00150","title":"00150","hpath":"games.tis-100.segment.00150","content":"\n# Self-Test Diagnostic\n\n# Solution\n\n```\n@0\nMOV UP,DOWN\n\n@1\nMOV RIGHT, DOWN\n\n@2\nMOV UP,LEFT\n\n@3\nMOV UP, DOWN\n\n@4\nMOV UP,DOWN\n\n@5\nMOV UP, DOWN\n\n@6\nMOV UP,RIGHT\n\n@7\nMOV LEFT,DOWN\n```\n\n# Solution\n\n![](/assets/images/2020-10-25-21-45-52.png)","url":"https://deltamaniac.github.io/notes/2f9f6f35-8e0d-4016-b62b-8c76b7710d46.html","relUrl":"notes/2f9f6f35-8e0d-4016-b62b-8c76b7710d46.html"},{"doc":"Destiny","title":"Destiny","hpath":"games.destiny","content":"\n","url":"https://deltamaniac.github.io/notes/317f9bc7-7931-429b-9fa9-1737534e8a1a.html","relUrl":"notes/317f9bc7-7931-429b-9fa9-1737534e8a1a.html"},{"doc":"Gamerdungeon","title":"Gamerdungeon","hpath":"games.destiny.gamerdungeon","content":"\n","url":"https://deltamaniac.github.io/notes/022f0d91-14d1-4ee7-904b-18f474b84c49.html","relUrl":"notes/022f0d91-14d1-4ee7-904b-18f474b84c49.html"},{"doc":"Lore","title":"Lore","hpath":"games.destiny.gamerdungeon.lore","content":"\n","url":"https://deltamaniac.github.io/notes/aac395c2-48dc-4c24-afb8-310bb7757e54.html","relUrl":"notes/aac395c2-48dc-4c24-afb8-310bb7757e54.html"},{"doc":"Zek","title":"Zek","hpath":"games.destiny.gamerdungeon.lore.zek","content":"\n++ The Archives of T√ù-√π√º√± ++\nCodex Entry : ¬ß585--1874¬ß\nTitle : [ERR-7634]...Zek Tras Resnaz\nContent:\n\n    Knowledge, absolutely sure of its infallibility, is faith\n\nWarlocks are the scholars of our world. They spend great many ages pursuing the knowledge that makes them whole. Zek Tras Resnaz was one such warlock, and her poison was the infamous black armoury papers. To Zek they meant more than just knowledge, she thought it was meant to lead the way to the most powerful weapons in the universe.. to protect humanity. To her this meant the tireless pursuit of using the great forges of old to forge weapon after weapon in order to find the perfect weapon with which she could protect herself. Just like any other warlock, she was had contempt for the titans and the hunters around her. Titans those buffoons who only care about punching things and those hunters who just didn't care about any higher purpose other than themselves. She always wondered why did Ikora even listen to Zavala, he was not fit to be the leader of the vanguard, the man didn't even know anything about the history of the golden age or even talked to Ada-1.\n...\n[ERR-7634]\n...\nSiviks was her nemesis as he was the one who used the great forge of Gofannon and tainted it. This was heresy and Siviks and his Kell's Scourge would have to pay the price. She knew that he was here on earth, and had defiled the greatest vault of the black armory and stole its content. She quickly guided here fireteam of lesser gaurdians to the vault, but she was too late. Sivik's had mocked her again and fled.. however this made her resolve absolute, **Siviks Must Die, I shall be the bane of Kells Scourge**\n...\n[ERR-7634]\n[ERR-9532]\n[ERR-0001]\n.... Aborting archive reconstruction.. too many errors to continue grammar reconstruction.","url":"https://deltamaniac.github.io/notes/81183eb8-e34d-4588-aff1-bd8592e91791.html","relUrl":"notes/81183eb8-e34d-4588-aff1-bd8592e91791.html"},{"doc":"Swift","title":"Swift","hpath":"games.destiny.gamerdungeon.lore.swift","content":"\n","url":"https://deltamaniac.github.io/notes/ea93896f-e8c2-49c3-a90f-5ebe71795a75.html","relUrl":"notes/ea93896f-e8c2-49c3-a90f-5ebe71795a75.html"},{"doc":"Lucan","title":"Lucan","hpath":"games.destiny.gamerdungeon.lore.lucan","content":"\n","url":"https://deltamaniac.github.io/notes/2bfcbd54-a3b5-40dc-9192-4f7607233d13.html","relUrl":"notes/2bfcbd54-a3b5-40dc-9192-4f7607233d13.html"},{"doc":"Chimi","title":"Chimi","hpath":"games.destiny.gamerdungeon.lore.chimi","content":"\n++ The Archives of T√ù-√π√º√± ++\nCodex Entry : ¬ß145--124¬ß\nTitle : [ERR-7634]...Chimichanga\nContent:\n\nWhat connects 20000 years of Genocide? Too much power in a single hand\n\n[ERR-7634]\nThere use be an all powerful \"Chimichanga\", powerful enough that the rivers flowed as his will decided. The flora and fauna were overwhelmed by his willpower that they could feel their very essence of soul being burnt up, their physical form fades to dust. He attained the power of such magnitude not by chance, but pure will and a cold and unwavering heart.\n...\n[ERR-7634]\n...\nIn his duel with the great protector of ≈†z≈∏-√êN√íX Saint Lucan1x he had become too overconfident in his power that he thought the Saint wouldn't be able to shoot let alone kill him if he couldn't be seen. He could just disappear from the visual spectrum of Saint and simple Solar Infused knife thrown from the back would be the first and last blow for this so called \"saint among peasants\". He infused the blade in his hand with his will and it shone red with heat and hatred, threw it at the saints back. As the knife was flying through the air the Saint started shimmering with a purple glow, the air around him rippling with energy. As the knife moved closer its pace increased and so did its weight, as was the will of it creator. Just before it could hit saints neck a purple disc appeared in its path. The knife disintegrated upon hitting it and before the knife thrower could blink he heard the shot of a long lost weapon of legend, the weapon that wielded the power of a small star, Izanagi's Burden. The next thing he felt was his soul, his will and his body splitting apart from each other. \"How had he lost ?\" was the last thought that crossed his mind before darkness enveloped him.\n...\n[ERR-7634]\n[ERR-9532]\n[ERR-0001]\n\n.... Aborting archive reconstruction.. too many errors to continue grammar reconstruction.","url":"https://deltamaniac.github.io/notes/b4d422fa-d456-428e-8e48-b3d6b2a5cbcb.html","relUrl":"notes/b4d422fa-d456-428e-8e48-b3d6b2a5cbcb.html"},{"doc":"Advent of Code","title":"Advent of Code","hpath":"aoc","content":"\nAdvent of Code is an Advent calendar of small programming puzzles for a variety of skill sets and skill levels that can be solved in any programming language you like. People use them as a speed contest, interview prep, company training, university coursework, practice problems, or to challenge each other.\n","url":"https://deltamaniac.github.io/notes/941adaa5-d22f-4bf9-831a-35bb5ac4100c.html","relUrl":"notes/941adaa5-d22f-4bf9-831a-35bb5ac4100c.html"},{"doc":"2015","title":"2015","hpath":"aoc.2015","content":"\n","url":"https://deltamaniac.github.io/notes/bb5ef214-cf28-4a7d-9c1e-15e8e9829ca3.html","relUrl":"notes/bb5ef214-cf28-4a7d-9c1e-15e8e9829ca3.html"},{"doc":"Day 5","title":"Day 5","hpath":"aoc.2015.d5","content":"\n# Doesn't He Have Intern-Elves For This?\n\n## Part I\n\nSanta needs help figuring out which strings in his text file are naughty or nice.\n\nA nice string is one with all of the following properties:\n\n> It contains at least three vowels (`aeiou` only), like `aei`, `xazegov`, or `aeiouaeiouaeiou`.\n>\n>It contains at least one letter that appears twice in a row, like `xx`, `abcdde` (`dd`), or `aabbccdd` (`aa`, `bb`, `cc`, or `dd`).\n>\n>It does not contain the strings `ab`, `cd`, `pq`, or `xy`, even if they are part of one of the other requirements.\n\nFor example:\n\n> `ugknbfddgicrmopn` is nice because it has at least three vowels (`u...i...o...`), a double letter (`...dd...`), and none of the disallowed substrings.\n>\n>`aaa` is nice because it has at least three vowels and a double letter, even though the letters used by different rules overlap.\n>\n>`jchzalrnumimnmhp` is naughty because it has no double letter.\n>\n>`haegwjzuvuyypxyu` is naughty because it contains the string xy.\n>\n>`dvszwmarrgswjxmb` is naughty because it contains only one vowel.\n\nHow many strings are nice?\n\n## Solution\nIterating the input line by line we can pass it through filters which would apply the conditions so as to eliminate all strings that are not `nice`.\n\nThe answer is the count of all the remaining strings.\n\n```rust\n#[aoc(day5, part1)]\npub fn part1(input: &str) -> usize {\n    input\n        .lines()\n        .filter(|w| !(w.contains(\"ab\") || w.contains(\"cd\") || w.contains(\"pq\") || w.contains(\"xy\")))\n        .filter(|x| {\n            x.chars()\n                .filter(|c| *c == 'a' || *c == 'e' || *c == 'i' || *c == 'o' || *c == 'u')\n                .count()\n                > 2\n        })\n        .filter(|y| {\n            let mut c = y.chars().collect::<Vec<char>>();\n            let l = c.len();\n            c.dedup();\n            l != c.len()\n        })\n        .count()\n}\n```\n\n## Part II\n\nRealizing the error of his ways, Santa has switched to a better model of determining whether a string is naughty or nice. None of the old rules apply, as they are all clearly ridiculous.\n\nNow, a nice string is one with all of the following properties:\n\n>It contains a pair of any two letters that appears at least twice in the string without overlapping, like `xyxy` (`xy`) or `aabcdefgaa` (`aa`), but not like `aaa` (`aa`, but it overlaps).\n>\n>It contains at least one letter which repeats with exactly one letter between them, like `xyx`, `abcdefeghi` (`efe`), or even `aaa`.\n\n\nFor example:\n> `qjhvhtzxzqqjkmpb` is nice because is has a pair that appears twice (`qj`) and a letter that repeats with exactly one letter between them (`zxz`).\n>\n> `xxyxx` is nice because it has a pair that appears twice and a letter that repeats with one between, even though the letters used by each rule overlap.\n>\n> `uurcxstgmygtbstg` is naughty because it has a pair (`tg`) but no repeat with a single letter between them.\n>\n> `ieodomkazucvgmuy` is naughty because it has a repeating letter with one between (`odo`), but no pair that appears twice.\n\nHow many strings are nice under these new rules?\n\n## Solution\nA recursive function `repeat_xx` provides the check for condition we then filter out on the strings that match.\n\nThe answer is the count of all the remaining strings after the filters have been applied.\n\n```rust\nfn repeat_xx(string: &str) -> bool {\n    if string.len() < 4 {\n        return false;\n    }\n\n    let pair = &string[0..2];\n    let remain = &string[2..];\n\n    remain.contains(pair) || repeat_xx(&string[1..])\n}\n\n#[aoc(day5, part2)]\npub fn part2(input: &str) -> usize {\n    input\n        .lines()\n        .filter(|y| repeat_xx(y))\n        .filter(|z| z.chars().zip(z.chars().skip(2)).any(|(a, b)| a == b))\n        .count()\n}\n```","url":"https://deltamaniac.github.io/notes/80d4a8ee-94fa-4b37-aabd-eb6fcc053d21.html","relUrl":"notes/80d4a8ee-94fa-4b37-aabd-eb6fcc053d21.html"},{"doc":"Day 4","title":"Day 4","hpath":"aoc.2015.d4","content":"\n# The Ideal Stocking Stuffer\n\n## Part I\n\nSanta needs help mining some AdventCoins (very similar to bitcoins) to use as gifts for all the economically forward-thinking little girls and boys.\n\nTo do this, he needs to find MD5 hashes which, in hexadecimal, start with at least five zeroes. The input to the MD5 hash is some secret key (your puzzle input, given below) followed by a number in decimal. To mine AdventCoins, you must find Santa the lowest positive number (no leading zeroes: `1`, `2`, `3`, ...) that produces such a hash.\n\nFor example:\n\n> If your secret key is `abcdef`, the answer is `609043`, because the MD5 hash of `abcdef609043` starts with five zeroes (`000001dbbfa...`), and it is the lowest such number to do so.\n>\n> If your secret key is `pqrstuv`, the lowest number it combines with to make an MD5 hash starting with five zeroes is `1048970`; that is, the MD5 hash of `pqrstuv1048970` looks like `000006136ef....`\n\n## Solution\n\nBrute forcing would be the easiest way to find the solution.\n\nTaking the input we iterate from 1 to the max u32 using `i` and append it to the input.\n\nThis would be the content for which we compute the`md5Sum` and check if it starts with five zeroes.\n```rust\nuse md5;\n\n#[aoc(day4, part1)]\npub fn solve_part1(input: &str) -> u32 {\n    (1..)\n        .filter(|i| format!(\"{:x}\", md5::compute(format!(\"{}{}\", input, i))).starts_with(\"00000\"))\n        .next()\n        .unwrap()\n}\n```\n\n## Part II\n\n\nNow find one that starts with six zeroes.\n\n## Solution\n\nA small change from `.starts_with(\"00000\")` to `.starts_with(\"000000\")` provides the answer.\n\n```rust\n#[aoc(day4, part2)]\npub fn solve_part2(input: &str) -> i32 {\n    (1..)\n        .filter(|i| format!(\"{:x}\", md5::compute(format!(\"{}{}\", input, i))).starts_with(\"000000\"))\n        .next()\n        .unwrap()\n}\n```","url":"https://deltamaniac.github.io/notes/f6d391d5-db6b-46bb-a432-4a6592355b34.html","relUrl":"notes/f6d391d5-db6b-46bb-a432-4a6592355b34.html"},{"doc":"Day 3","title":"Day 3","hpath":"aoc.2015.d3","content":"\n# Perfectly Spherical Houses in a Vacuum\n\n## Part I\n\nSanta is delivering presents to an infinite two-dimensional grid of houses.\n\nHe begins by delivering a present to the house at his starting location, and then an elf at the North Pole calls him via radio and tells him where to move next. Moves are always exactly one house to the north (`^`), south (`v`), east (`>`), or west (`<`). After each move, he delivers another present to the house at his new location.\n\nHowever, the elf back at the north pole has had a little too much eggnog, and so his directions are a little off, and Santa ends up visiting some houses more than once. How many houses receive at least one present?\n\nFor example:\n\n> `>` delivers presents to 2 houses: one at the starting location, and one to the east.\n>\n> `^>v<` delivers presents to 4 houses in a square, including twice to the house at his starting/ending location.\n>\n> `^v^v^v^v^v` delivers a bunch of presents to some very lucky children at only 2 houses.\n\n## Solution\n\nA simple XY coordinate system would make this a simple pathing problem.\n\nThe `last_pos` variable would hold the (x,y) coordinates of Santa.\n\nA hashmap with the key as the (x,y) coordinate will be used to identify individual houses and store the number of presents delivered at that house.\n\n```rust\n#[aoc(day3, part1)]\npub fn part1(input: &str) -> usize {\n    let mut last_pos = (0, 0);\n    let mut map: HashMap<(i32, i32), u32> = HashMap::new();\n    map.insert(last_pos, 0);\n    input.chars().for_each(|d| {\n        last_pos = match d {\n            '^' => (last_pos.0 + 1, last_pos.1),\n            'v' => (last_pos.0 - 1, last_pos.1),\n            '>' => (last_pos.0, last_pos.1 + 1),\n            '<' => (last_pos.0, last_pos.1 - 1),\n            _ => unreachable!(),\n        };\n        map.entry(last_pos).and_modify(|x| *x += 1).or_insert(1);\n    });\n    map.len()\n}\n```\n\n## Part II\nThe next year, to speed up the process, Santa creates a robot version of himself, Robo-Santa, to deliver presents with him.\n\nSanta and Robo-Santa start at the same location (delivering two presents to the same starting house), then take turns moving based on instructions from the elf, who is eggnoggedly reading from the same script as the previous year.\n\nThis year, how many houses receive at least one present?\n\nFor example:\n\n> `^v` delivers presents to 3 houses, because Santa goes north, and then Robo-Santa goes south.\n>\n> `^>v<` now delivers presents to `3` houses, and Santa and Robo-Santa end up back where they started.\n>\n> `^v^v^v^v^v` now delivers presents to `11` houses, with Santa going one direction and Robo-Santa going the other.\n\n## Solution\n\nHere we would have to trace 2 paths, one for Santa and another for Robo-Santa.\n\nSince both of them take turns reading the instructions, Santa received all odd numbered instructions and the Robo-Santa receives all even numbered instructions.\n\n```rust\n#[aoc(day3, part2)]\npub fn part2(input: &str) -> usize {\n    let mut last_pos = (0, 0);\n    let mut last_pos_clone = (0, 0);\n    let mut map: HashMap<(i32, i32), u32> = HashMap::new();\n    map.insert(last_pos, 0);\n    input.chars().enumerate().for_each(|(i, d)| {\n        if i % 2 == 0 {\n            last_pos = match d {\n                '^' => (last_pos.0 + 1, last_pos.1),\n                'v' => (last_pos.0 - 1, last_pos.1),\n                '>' => (last_pos.0, last_pos.1 + 1),\n                '<' => (last_pos.0, last_pos.1 - 1),\n                _ => unreachable!(),\n            };\n            map.entry(last_pos).and_modify(|x| *x += 1).or_insert(1);\n        } else {\n            last_pos_clone = match d {\n                '^' => (last_pos_clone.0 + 1, last_pos_clone.1),\n                'v' => (last_pos_clone.0 - 1, last_pos_clone.1),\n                '>' => (last_pos_clone.0, last_pos_clone.1 + 1),\n                '<' => (last_pos_clone.0, last_pos_clone.1 - 1),\n                _ => unreachable!(),\n            };\n            map.entry(last_pos_clone)\n                .and_modify(|x| *x += 1)\n                .or_insert(1);\n        }\n    });\n    map.len()\n}\n```","url":"https://deltamaniac.github.io/notes/17fb47c1-bbab-4343-bdb4-3e9910c24944.html","relUrl":"notes/17fb47c1-bbab-4343-bdb4-3e9910c24944.html"},{"doc":"Day 2","title":"Day 2","hpath":"aoc.2015.d2","content":"\n#  I Was Told There Would Be No Math\n\n## Part I\n\nThe elves are running low on wrapping paper, and so they need to submit an order for more. They have a list of the dimensions (length `l`, width `w`, and height `h`) of each present, and only want to order exactly as much as they need.\n\nFortunately, every present is a box (a perfect right rectangular prism), which makes calculating the required wrapping paper for each gift a little easier: find the surface area of the box, which is `2*l*w + 2*w*h + 2*h*l`. The elves also need a little extra paper for each present: the area of the smallest side.\n\nFor example:\n\n> A present with dimensions `2x3x4` requires `2*6 + 2*12 + 2*8 = 52` square feet of wrapping paper plus `6` square feet of slack, for a total of `58` square feet.\n>\n> A present with dimensions `1x1x10` requires `2*1 + 2*10 + 2*10 = 42` square feet of wrapping paper plus `1` square foot of slack, for a total of `43` square feet.\n\nAll numbers in the elves' list are in feet. How many total square feet of wrapping paper should they order?\n\n## Solution\n\nA simple structure that can hold the dimensions would be the starting point from which we can solve the problem.\n\nA method `get_area` that would return the area calculated as `2*l*w + 2*w*h + 2*h*l`.\n\nA method `get_smallest_side_area` would calculate all the side areas and return the minimum which would provide the `slack` to be added.\n\nA `text_to_struct` method that would convert the text input to a `Vector` of `Prism`, to enable easy iteration.\n\nTo find the answer iterate over the Vector<Prism> calculate the `area` + `smallest_side_area` and sum them all up.\n\n```rust\n// Holds the dimensions of the Gift\n#[derive(Copy, Clone)]\npub struct Prism {\n    x: u32,\n    y: u32,\n    z: u32,\n}\n\nimpl Prism {\n\n    pub fn get_smallest_side_area(self) -> u32 {\n        *[self.x * self.y, self.y * self.z, self.z * self.x]\n            .iter()\n            .min()\n            .unwrap_or(&0)\n    }\n\n    pub fn get_area(self) -> u32 {\n        [\n            2 * self.x * self.y,\n            2 * self.y * self.z,\n            2 * self.z * self.x,\n        ]\n        .iter()\n        .sum::<u32>()\n    }\n}\n\n#[aoc_generator(day2)]\npub fn text_to_struct(input: &str) -> Vec<Prism> {\n    input\n        .lines()\n        .map(|line| {\n            let mut chars = line.trim().split('x');\n            Prism {\n                x: chars.next().unwrap().parse().unwrap(),\n                y: chars.next().unwrap().parse().unwrap(),\n                z: chars.next().unwrap().parse().unwrap(),\n            }\n        })\n        .collect::<Vec<Prism>>()\n}\n\n#[aoc(day2, part1)]\npub fn part1(input: &[Prism]) -> u32 {\n    input\n        .iter()\n        .map(|x| x.get_smallest_side_area() + x.get_area())\n        .collect::<Vec<u32>>()\n        .iter()\n        .sum()\n}\n```\n\n## Part II\n\nThe elves are also running low on ribbon. Ribbon is all the same width, so they only have to worry about the length they need to order, which they would again like to be exact.\n\nThe ribbon required to wrap a present is the shortest distance around its sides, or the smallest perimeter of any one face. Each present also requires a bow made out of ribbon as well; the feet of ribbon required for the perfect bow is equal to the cubic feet of volume of the present. Don't ask how they tie the bow, though; they'll never tell.\n\nFor example:\n> A present with dimensions `2x3x4` requires `2+2+3+3 = 10` feet of ribbon to wrap the present plus `2*3*4 = 24` feet of ribbon for the bow, for a total of `34` feet.\n>\n> A present with dimensions `1x1x10` requires `1+1+1+1 = 4` feet of ribbon to wrap the present plus `1*1*10 = 10` feet of ribbon for the bow, for a total of `14` feet.\n\nHow many total feet of ribbon should they order?\n\n## Solution\n\nA method `get_smallest_perimeter` that would return the smallest perimeter of the prism.\n\nTo find the answer iterate over the Vector<Prism> calculate the `smallest_perimeter` + `sum of the sides of the smallest perimeter` and sum them all up.\n\n```rust\nimpl Prism {\n    pub fn get_smallest_side_area(self) -> u32 {\n        *[self.x * self.y, self.y * self.z, self.z * self.x]\n            .iter()\n            .min()\n            .unwrap_or(&0)\n    }\n\n    pub fn get_area(self) -> u32 {\n        [\n            2 * self.x * self.y,\n            2 * self.y * self.z,\n            2 * self.z * self.x,\n        ]\n        .iter()\n        .sum::<u32>()\n    }\n    // PART 2\n    pub fn get_smallest_perimeter(self) -> u32 {\n        *[\n            2 * (self.x + self.y),\n            2 * (self.y + self.z),\n            2 * (self.z + self.x),\n        ]\n        .iter()\n        .min()\n        .unwrap_or(&0)\n    }\n}\n\n#[aoc(day2, part2)]\npub fn part2(input: &[Prism]) -> u32 {\n    input\n        .iter()\n        .map(|x| x.get_smallest_perimeter() + (x.x * x.y * x.z))\n        .collect::<Vec<u32>>()\n        .iter()\n        .sum()\n}\n\n```","url":"https://deltamaniac.github.io/notes/0359877a-1c2d-4363-aef5-41dcb3d086ca.html","relUrl":"notes/0359877a-1c2d-4363-aef5-41dcb3d086ca.html"},{"doc":"Day 1","title":"Day 1","hpath":"aoc.2015.d1","content":"\n# Not Quite Lisp\n\nSanta was hoping for a white Christmas, but his weather machine's \"snow\" function is powered by stars, and he's fresh out! To save Christmas, he needs you to collect fifty stars by December 25th.\n\n## Part I\nSanta is trying to deliver presents in a large apartment building, but he can't find the right floor - the directions he got are a little confusing.\n He starts on the ground floor (floor `0`) and then follows the instructions one character at a time.\n\nAn opening parenthesis, `(`, means he should go up one floor, and a closing parenthesis, ), means he should go down one floor.\n\nThe apartment building is very tall, and the basement is very deep; he will never find the top or bottom floors.\n\nFor example:\n> `(())` and `()()` both result in floor `0`.\n>\n>`(((` and `(()(()(` both result in floor `3`.\n>\n>`))(((((` also results in floor `3`.\n>\n>`())` and `))(` both result in floor `-1` (the first basement\nlevel).\n>\n>`)))` and `)())())` both result in floor `-3`.\n\n\nTo what floor do the instructions take Santa?\n\n## Solution\n\nThe easiest way to solve this problem would be to split the input string into chars and iterate over each character.\n\nAfter that we use the [iterator::fold](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.fold) method of the iterator over the characters.\n\nFor each `(` we increment a sum value by 1 and for ')' we decrement a sum value by 1.\n```rust\n#[aoc(day1, part1)]\npub fn part1(input: &str) -> i32 {\n    input.chars().fold(0, |sum, c| match c {\n        '(' => sum + 1,\n        ')' => sum - 1,\n        _ => unreachable!(),\n    })\n}\n```\n\n## Part II\n\nNow, given the same instructions, find the position of the first character that causes him to enter the basement (floor -1).\n\n The first character in the instructions has position 1, the second character has position 2, and so on.\n\nFor example:\n\n> `)` causes him to enter the basement at character position `1`.\n>\n> `()())` causes him to enter the basement at character position `5`.\n\nWhat is the position of the character that causes Santa to first enter the basement?\n\n## Solution\nThe easiest way to solve this would be be to keep a check if the sum value every becomes less than 0.\n\nThis condition can be easily identified by using the [checked_sub](https://doc.rust-lang.org/std/primitive.isize.html#method.checked_sub)\n```rust\n#[aoc(day1, part2)]\npub fn part2(input: &str) -> usize {\n    let mut sum: u32 = 0;\n    for (i, c) in input.chars().enumerate() {\n        match c {\n            '(' => sum += 1,\n            ')' => {\n                if let Some(s) = sum.checked_sub(1) {\n                    sum = s;\n                } else {\n                    return i + 1;\n                }\n            }\n            _ => unreachable!(),\n        }\n    }\n    unreachable!()\n}\n```","url":"https://deltamaniac.github.io/notes/dcb2143d-1df6-4c9e-9289-cbc76082ace2.html","relUrl":"notes/dcb2143d-1df6-4c9e-9289-cbc76082ace2.html"}]
